{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro<br>\n",
    "PCA + Local Outlier Factor used to detect anomalies. Results are later graded using the risk indicators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# sys.path.append(r\"E:\\enyutan\\Document\\2025 MJE Advanced Analytics\\Ishi\")\n",
    "import _00_util_sql\n",
    "reload(_00_util_sql)\n",
    "from _00_util_sql import Conn_ODBC\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Import Sales data \n",
    "sql_db=Conn_ODBC(database=\"JE_ML_2025\")\n",
    "conn=sql_db.odbc_conn_db_pyodbc()\n",
    "# sql_query=f\"SELECT * FROM [cluster_22_clustered]\"\n",
    "# sql_query=f\"SELECT * FROM [cluster_21_clustered_separate]\"\n",
    "# sql_query=f\"SELECT * FROM [cluster_21_clustered_merged]\"\n",
    "# sql_query=f\"SELECT * FROM [data_p_ishi_GL_JE_cleaned_2019] WHERE AccDocNo LIKE '99%'\"\n",
    "\n",
    "sales_df=sql_db.odbc_run_sql(conn, sql_query, return_result=True)\n",
    "conn.close()\n",
    "# 1-2 mins\n",
    "\n",
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18992 entries, 0 to 18991\n",
      "Data columns (total 64 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   FiscalYear                                  18992 non-null  int64  \n",
      " 1   AccDocNo                                    18992 non-null  int64  \n",
      " 2   Dr_Cr                                       18992 non-null  object \n",
      " 3   DateOfAccDocEntry                           18992 non-null  object \n",
      " 4   DateOfAccDocEntry_and_TimeOfEntry (MYT)     18992 non-null  object \n",
      " 5   NoOfLineItemInAccDoc                        18992 non-null  object \n",
      " 6   RefKeyForLineItem                           18992 non-null  object \n",
      " 7   GL_DESCRIPTION                              18992 non-null  object \n",
      " 8   Amt_localCurrencyFormatted                  18992 non-null  object \n",
      " 9   Document Type Description                   18992 non-null  object \n",
      " 10  Quantity                                    18992 non-null  object \n",
      " 11  Username                                    18992 non-null  object \n",
      " 12  TransactionCode                             10679 non-null  object \n",
      " 13  DocHeaderText                               0 non-null      float64\n",
      " 14  IsDocReversalOrReversedDoc                  136 non-null    float64\n",
      " 15  IdOfLineItem                                18992 non-null  object \n",
      " 16  PostingKey                                  18992 non-null  object \n",
      " 17  isLineItemAutomaticallyCreated              18992 non-null  object \n",
      " 18  TermsOfPayment                              18992 non-null  object \n",
      " 19  CashDiscountAmountInLocalCurrency           18992 non-null  object \n",
      " 20  PaymentMethod                               18992 non-null  object \n",
      " 21  Plant                                       18992 non-null  object \n",
      " 22  hasSubsequentDrCrMemo                       18992 non-null  object \n",
      " 23  WBSElement                                  18992 non-null  object \n",
      " 24  SpecialGLIndicator                          18992 non-null  object \n",
      " 25  GL_AccType_AccountTypeDesc                  18992 non-null  object \n",
      " 26  Username Type                               18992 non-null  object \n",
      " 27  Amt_DocCurrency_NoOfTrailingZeroes          18992 non-null  object \n",
      " 28  CashDiscountPercentage                      18992 non-null  object \n",
      " 29  IND_MonthEnd                                18992 non-null  int64  \n",
      " 30  IND_QuarterEnd                              18992 non-null  int64  \n",
      " 31  IND_YearEnd                                 18992 non-null  int64  \n",
      " 32  IND_Weekend                                 18992 non-null  int64  \n",
      " 33  IND_PublicHol                               18992 non-null  int64  \n",
      " 34  IND_OutsideWorkHours                        18992 non-null  int64  \n",
      " 35  labelled_GL_AccType                         18992 non-null  object \n",
      " 36  labelled_AccountTypeDesc                    18992 non-null  object \n",
      " 37  labelled_GL_AccType_AccountTypeDesc         18992 non-null  object \n",
      " 38  labelled_GL_DESCRIPTION                     18992 non-null  object \n",
      " 39  labelled_Document Type Description          18992 non-null  int64  \n",
      " 40  labelled_Username                           18992 non-null  object \n",
      " 41  labelled_TransactionCode                    18992 non-null  int64  \n",
      " 42  labelled_IdOfLineItem                       18992 non-null  object \n",
      " 43  labelled_PostingKey                         18992 non-null  object \n",
      " 44  labelled_isLineItemAutomaticallyCreated     18992 non-null  object \n",
      " 45  labelled_TermsOfPayment                     18992 non-null  object \n",
      " 46  labelled_PaymentMethod                      18992 non-null  object \n",
      " 47  labelled_FollowOnDocType                    18992 non-null  object \n",
      " 48  labelled_Plant                              18992 non-null  object \n",
      " 49  labelled_Username Type                      18992 non-null  int64  \n",
      " 50  Cr_Asset - Customer                         18992 non-null  float64\n",
      " 51  Cr_Asset - G\\L Account                      18992 non-null  float64\n",
      " 52  Cr_Cost of Goods Sold (COGS) - G\\L Account  18992 non-null  float64\n",
      " 53  Cr_Liability - G\\L Account                  18992 non-null  float64\n",
      " 54  Cr_Other Costs - G\\L Account                18992 non-null  float64\n",
      " 55  Cr_Other Revenue - G\\L Account              18992 non-null  float64\n",
      " 56  Cr_Revenue - G\\L Account                    18992 non-null  float64\n",
      " 57  Dr_Asset - Customer                         18992 non-null  float64\n",
      " 58  Dr_Asset - G\\L Account                      18992 non-null  float64\n",
      " 59  Dr_Cost of Goods Sold (COGS) - G\\L Account  18992 non-null  float64\n",
      " 60  Dr_Liability - G\\L Account                  18992 non-null  float64\n",
      " 61  Dr_Other Costs - G\\L Account                18992 non-null  float64\n",
      " 62  Dr_Other Revenue - G\\L Account              18992 non-null  float64\n",
      " 63  Dr_Revenue - G\\L Account                    18992 non-null  float64\n",
      "dtypes: float64(16), int64(11), object(37)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "siewdf = pd.read_csv(rf\"D:\\victoriaquek\\JE ML 2025\\Results\\data_p_ishi_GL_JE_cleaned_SIEWPL\", index_col=0)\n",
    "siewdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18992 entries, 0 to 18991\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   FiscalYear                                  18992 non-null  int64  \n",
      " 1   AccDocNo                                    18992 non-null  int64  \n",
      " 2   Dr_Cr                                       18992 non-null  object \n",
      " 3   DateOfAccDocEntry                           18992 non-null  object \n",
      " 4   DateOfAccDocEntry_and_TimeOfEntry (MYT)     18992 non-null  object \n",
      " 5   NoOfLineItemInAccDoc                        18992 non-null  object \n",
      " 6   RefKeyForLineItem                           18992 non-null  object \n",
      " 7   GL_DESCRIPTION                              18992 non-null  object \n",
      " 8   Amt_localCurrencyFormatted                  18992 non-null  object \n",
      " 9   Document Type Description                   18992 non-null  object \n",
      " 10  Quantity                                    18992 non-null  object \n",
      " 11  Username                                    18992 non-null  object \n",
      " 12  TransactionCode                             10679 non-null  object \n",
      " 13  IsDocReversalOrReversedDoc                  136 non-null    float64\n",
      " 14  IdOfLineItem                                18992 non-null  object \n",
      " 15  PostingKey                                  18992 non-null  object \n",
      " 16  isLineItemAutomaticallyCreated              18992 non-null  object \n",
      " 17  TermsOfPayment                              18992 non-null  object \n",
      " 18  CashDiscountAmountInLocalCurrency           18992 non-null  object \n",
      " 19  PaymentMethod                               18992 non-null  object \n",
      " 20  Plant                                       18992 non-null  object \n",
      " 21  hasSubsequentDrCrMemo                       18992 non-null  object \n",
      " 22  WBSElement                                  18992 non-null  object \n",
      " 23  SpecialGLIndicator                          18992 non-null  object \n",
      " 24  GL_AccType_AccountTypeDesc                  18992 non-null  object \n",
      " 25  Username Type                               18992 non-null  object \n",
      " 26  Amt_DocCurrency_NoOfTrailingZeroes          18992 non-null  object \n",
      " 27  CashDiscountPercentage                      18992 non-null  object \n",
      " 28  IND_MonthEnd                                18992 non-null  int64  \n",
      " 29  IND_QuarterEnd                              18992 non-null  int64  \n",
      " 30  IND_YearEnd                                 18992 non-null  int64  \n",
      " 31  IND_Weekend                                 18992 non-null  int64  \n",
      " 32  IND_PublicHol                               18992 non-null  int64  \n",
      " 33  IND_OutsideWorkHours                        18992 non-null  int64  \n",
      " 34  labelled_GL_AccType                         18992 non-null  object \n",
      " 35  labelled_AccountTypeDesc                    18992 non-null  object \n",
      " 36  labelled_GL_AccType_AccountTypeDesc         18992 non-null  object \n",
      " 37  labelled_GL_DESCRIPTION                     18992 non-null  object \n",
      " 38  labelled_Document Type Description          18992 non-null  int64  \n",
      " 39  labelled_Username                           18992 non-null  object \n",
      " 40  labelled_TransactionCode                    18992 non-null  int64  \n",
      " 41  labelled_IdOfLineItem                       18992 non-null  object \n",
      " 42  labelled_PostingKey                         18992 non-null  object \n",
      " 43  labelled_isLineItemAutomaticallyCreated     18992 non-null  object \n",
      " 44  labelled_TermsOfPayment                     18992 non-null  object \n",
      " 45  labelled_PaymentMethod                      18992 non-null  object \n",
      " 46  labelled_FollowOnDocType                    18992 non-null  object \n",
      " 47  labelled_Plant                              18992 non-null  object \n",
      " 48  labelled_Username Type                      18992 non-null  int64  \n",
      " 49  Cr_Asset - Customer                         18992 non-null  float64\n",
      " 50  Cr_Asset - G\\L Account                      18992 non-null  float64\n",
      " 51  Cr_Cost of Goods Sold (COGS) - G\\L Account  18992 non-null  float64\n",
      " 52  Cr_Liability - G\\L Account                  18992 non-null  float64\n",
      " 53  Cr_Other Costs - G\\L Account                18992 non-null  float64\n",
      " 54  Cr_Other Revenue - G\\L Account              18992 non-null  float64\n",
      " 55  Cr_Revenue - G\\L Account                    18992 non-null  float64\n",
      " 56  Dr_Asset - Customer                         18992 non-null  float64\n",
      " 57  Dr_Asset - G\\L Account                      18992 non-null  float64\n",
      " 58  Dr_Cost of Goods Sold (COGS) - G\\L Account  18992 non-null  float64\n",
      " 59  Dr_Liability - G\\L Account                  18992 non-null  float64\n",
      " 60  Dr_Other Costs - G\\L Account                18992 non-null  float64\n",
      " 61  Dr_Other Revenue - G\\L Account              18992 non-null  float64\n",
      " 62  Dr_Revenue - G\\L Account                    18992 non-null  float64\n",
      "dtypes: float64(15), int64(11), object(37)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "sales_df = siewdf.loc[:, siewdf.notna().any()]\n",
    "sales_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "amounts = [\n",
    "'Cr_Asset - Asset',\n",
    "'Cr_Asset - Customer', \n",
    "'Cr_Asset - G\\\\L Account', \n",
    "'Cr_Asset - Material',\n",
    "'Cr_Cost of Goods Sold (COGS) - G\\\\L Account',\n",
    "'Cr_Expense (6) - G\\\\L Account',\n",
    "'Cr_Liability - G\\\\L Account', \n",
    "'Cr_Liability - Vendor',\n",
    "'Cr_Other Costs - G\\\\L Account', \n",
    "'Cr_Other Revenue - G\\\\L Account', \n",
    "'Cr_Revenue - G\\\\L Account', \n",
    "'Dr_Asset - Asset', \n",
    "'Dr_Asset - Customer', \n",
    "'Dr_Asset - G\\\\L Account', \n",
    "'Dr_Asset - Material', \n",
    "'Dr_Cost of Goods Sold (COGS) - G\\\\L Account', \n",
    "'Dr_Expense (6) - G\\\\L Account', \n",
    "'Dr_Liability - G\\\\L Account', \n",
    "'Dr_Liability - Vendor', \n",
    "'Dr_Other Costs - G\\\\L Account', \n",
    "'Dr_Other Revenue - G\\\\L Account', \n",
    "'Dr_Revenue - G\\\\L Account'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "'GL_DESCRIPTION',\n",
    "'Amt_localCurrencyFormatted',\n",
    "'Document Type Description',\n",
    "'Username',\n",
    "'DocHeaderText',\n",
    "'IsDocReversalOrReversedDoc',\n",
    "'PostingKey',\n",
    "'isLineItemAutomaticallyCreated',\n",
    "'TermsOfPayment',\n",
    "'CashDiscountAmountInLocalCurrency',\n",
    "'PaymentMethod',\n",
    "'Plant',\n",
    "'WBSElement',\n",
    "'GL_AccType_AccountTypeDesc',\n",
    "'Username Type',\n",
    "'Amt_DocCurrency_NoOfTrailingZeroes',\n",
    "'CashDiscountPercentage',\n",
    "# 'IND_MonthEnd',\n",
    "# 'IND_QuarterEnd',\n",
    "# 'IND_YearEnd',\n",
    "# 'IND_Weekend',\n",
    "# 'IND_PublicHol',\n",
    "# 'IND_OutsideWorkHours',\n",
    "# 'SpecialGLIndicator',\n",
    "# 'hasSubsequentDrCrMemo',\n",
    "# 'IdOfLineItem',\n",
    "# 'TransactionCode',\n",
    "# 'Quantity',\n",
    "\n",
    "# New features from ZOTC\n",
    "# 'Carrier Key Desc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['labelled_GL_AccType_AccountTypeDesc',\n",
       " 'labelled_GL_DESCRIPTION',\n",
       " 'labelled_Document Type Description',\n",
       " 'labelled_Username',\n",
       " 'labelled_TransactionCode',\n",
       " 'labelled_IdOfLineItem',\n",
       " 'labelled_PostingKey',\n",
       " 'labelled_isLineItemAutomaticallyCreated',\n",
       " 'labelled_TermsOfPayment',\n",
       " 'labelled_PaymentMethod',\n",
       " 'labelled_FollowOnDocType',\n",
       " 'labelled_Plant',\n",
       " 'labelled_Username Type']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_cols = [col for col in sales_df.columns if col.startswith('labelled_')]\n",
    "print(len(encoded_cols))\n",
    "\n",
    "encoded_cols.remove('labelled_GL_AccType')\n",
    "encoded_cols.remove('labelled_AccountTypeDesc')\n",
    "print(len(encoded_cols))\n",
    "encoded_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cr_Other Revenue - G\\\\L Account',\n",
       " 'Cr_Revenue - G\\\\L Account',\n",
       " 'Dr_Other Revenue - G\\\\L Account',\n",
       " 'Dr_Revenue - G\\\\L Account']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List to store matches\n",
    "revenue_list = []\n",
    "\n",
    "# String to search for\n",
    "search_term = \"revenue\"\n",
    "\n",
    "# Case-insensitive search and add matches to new list\n",
    "for s in amounts:\n",
    "    if search_term.lower() in s.lower():\n",
    "        revenue_list.append(s)\n",
    "\n",
    "revenue_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_revenue(row, revenue_list):\n",
    "    total = 0\n",
    "    for col in revenue_list:\n",
    "        if col.startswith('Cr_'):\n",
    "            total -= row[col]\n",
    "        elif col.startswith('Dr_'):\n",
    "            total -= row[col]\n",
    "    return total\n",
    "\n",
    "# Apply function row-wise\n",
    "sales_df['Revenue'] = sales_df.apply(calculate_revenue, axis=1, revenue_list=revenue_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FiscalYear                                                                              2014\n",
       "AccDocNo                                                                          9900701945\n",
       "Dr_Cr                                      ['Dr', 'Cr', 'Cr', 'Dr', 'Cr', 'Dr', 'Cr', 'Dr...\n",
       "DateOfAccDocEntry                                                                 2014-01-09\n",
       "DateOfAccDocEntry_and_TimeOfEntry (MYT)                                  2014-01-09 16:32:24\n",
       "                                                                 ...                        \n",
       "Dr_Liability - G\\L Account                                                            715.75\n",
       "Dr_Other Costs - G\\L Account                                                             0.0\n",
       "Dr_Other Revenue - G\\L Account                                                           0.0\n",
       "Dr_Revenue - G\\L Account                                                                0.02\n",
       "Revenue                                                                              4408.15\n",
       "Name: 11, Length: 64, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sales_df.iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Columns to sum up\n",
    "# sum_cols = ['Amt_DocCurrency_NoOfTrailingZeroes', 'Quantity']\n",
    "\n",
    "# for col in sum_cols:\n",
    "#     sales_df[f'sum_{col}'] = sales_df[col].apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count distinct values for columns\n",
    "# def count_distinct_values(lst):\n",
    "#     return len(set(lst))\n",
    "\n",
    "# columns_to_d = ['IdOfLineItem', 'PostingKey', 'TermsOfPayment']\n",
    "\n",
    "# for col in columns_to_d:\n",
    "#     sales_df[f'distinct_{col}'] = sales_df[col].apply(count_distinct_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark if any 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = sales_df.copy()\n",
    "# df_result['Amt_DocCurrency_NoOfTrailingZeroes'].apply(lambda x: int(any(val > 0 for val in x)))\n",
    "# df_result['Amt_DocCurrency_NoOfTrailingZeroes_flag'] = df_result['Amt_DocCurrency_NoOfTrailingZeroes'].apply(\n",
    "#     lambda x: int(any(val > 0 for val in x))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def has_positive_string(x):\n",
    "    try:\n",
    "        # Convert string to actual list\n",
    "        values = ast.literal_eval(x) if isinstance(x, str) else x\n",
    "        # Check if any string in the list represents a number > 0\n",
    "        return int(any(float(val) > 0 for val in values))\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "df_result['Amt_DocCurrency_NoOfTrailingZeroes_flag'] = df_result['Amt_DocCurrency_NoOfTrailingZeroes'].apply(has_positive_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FiscalYear</th>\n",
       "      <th>AccDocNo</th>\n",
       "      <th>Dr_Cr</th>\n",
       "      <th>DateOfAccDocEntry</th>\n",
       "      <th>DateOfAccDocEntry_and_TimeOfEntry (MYT)</th>\n",
       "      <th>NoOfLineItemInAccDoc</th>\n",
       "      <th>RefKeyForLineItem</th>\n",
       "      <th>GL_DESCRIPTION</th>\n",
       "      <th>Amt_localCurrencyFormatted</th>\n",
       "      <th>Document Type Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Dr_Asset - G\\L Account</th>\n",
       "      <th>Dr_Cost of Goods Sold (COGS) - G\\L Account</th>\n",
       "      <th>Dr_Liability - G\\L Account</th>\n",
       "      <th>Dr_Other Costs - G\\L Account</th>\n",
       "      <th>Dr_Other Revenue - G\\L Account</th>\n",
       "      <th>Dr_Revenue - G\\L Account</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Amt_DocCurrency_NoOfTrailingZeroes_flag</th>\n",
       "      <th>EndCheck</th>\n",
       "      <th>OtherCheck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>9900467949</td>\n",
       "      <td>['Dr', 'Cr', 'Cr', 'Dr', 'Cr']</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-08 20:21:18</td>\n",
       "      <td>['001', '002', '003', '004', '005']</td>\n",
       "      <td>['5821-MRT-PMO-004', None, None, None, None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[3018.0, -2848.0, -284.0, 284.0, -170.0]</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>3018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>9900546273</td>\n",
       "      <td>['Dr', 'Cr']</td>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>2014-01-06 14:23:14</td>\n",
       "      <td>['001', '002']</td>\n",
       "      <td>[8500008426, None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[1280.0, -1280.0]</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>9900555709</td>\n",
       "      <td>['Dr', 'Cr']</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>2014-01-06 21:30:01</td>\n",
       "      <td>['001', '002']</td>\n",
       "      <td>[8400061160, None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[2128.0, -2128.0]</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>9900588004</td>\n",
       "      <td>['Dr', 'Cr', 'Cr', 'Cr']</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>2014-01-10 17:54:51</td>\n",
       "      <td>['001', '002', '003', '004']</td>\n",
       "      <td>[13012154, None, None, None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[201.0, -67.0, -67.0, -67.0]</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>9900634699</td>\n",
       "      <td>['Dr', 'Cr']</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>2014-01-02 19:09:35</td>\n",
       "      <td>['001', '002']</td>\n",
       "      <td>[626733, None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[66.0, -66.0]</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18987</th>\n",
       "      <td>2019</td>\n",
       "      <td>9950788382</td>\n",
       "      <td>['Cr', 'Dr']</td>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>2019-06-14 16:15:56</td>\n",
       "      <td>['001', '002']</td>\n",
       "      <td>['190240AUT', None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Marke...</td>\n",
       "      <td>[-20.0, 20.0]</td>\n",
       "      <td>Bill Doc.Tr - Cr Mem</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18988</th>\n",
       "      <td>2019</td>\n",
       "      <td>9950790111</td>\n",
       "      <td>['Cr', 'Dr']</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>2019-06-18 18:15:10</td>\n",
       "      <td>['001', '002']</td>\n",
       "      <td>['180414HPB(R1)', None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Vendo...</td>\n",
       "      <td>[-120.0, 120.0]</td>\n",
       "      <td>Bill Doc.Tr - Cr Mem</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18989</th>\n",
       "      <td>2019</td>\n",
       "      <td>9950790176</td>\n",
       "      <td>['Cr', 'Dr']</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>2019-06-18 18:15:51</td>\n",
       "      <td>['001', '002']</td>\n",
       "      <td>['180417HPW(R1)', None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Vendo...</td>\n",
       "      <td>[-150.0, 150.0]</td>\n",
       "      <td>Bill Doc.Tr - Cr Mem</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18990</th>\n",
       "      <td>2019</td>\n",
       "      <td>9950790623</td>\n",
       "      <td>['Cr', 'Dr']</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>2019-06-19 10:15:53</td>\n",
       "      <td>['001', '002']</td>\n",
       "      <td>['180416HPD(R1)', None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Vendo...</td>\n",
       "      <td>[-1700.0, 1700.0]</td>\n",
       "      <td>Bill Doc.Tr - Cr Mem</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18991</th>\n",
       "      <td>2019</td>\n",
       "      <td>9950793340</td>\n",
       "      <td>['Cr', 'Dr']</td>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>2019-06-25 14:15:11</td>\n",
       "      <td>['001', '002']</td>\n",
       "      <td>['190443APC', None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Marke...</td>\n",
       "      <td>[-4716.0, 4716.0]</td>\n",
       "      <td>Bill Doc.Tr - Cr Mem</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18992 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FiscalYear    AccDocNo                           Dr_Cr  \\\n",
       "0            2014  9900467949  ['Dr', 'Cr', 'Cr', 'Dr', 'Cr']   \n",
       "1            2014  9900546273                    ['Dr', 'Cr']   \n",
       "2            2014  9900555709                    ['Dr', 'Cr']   \n",
       "3            2014  9900588004        ['Dr', 'Cr', 'Cr', 'Cr']   \n",
       "4            2014  9900634699                    ['Dr', 'Cr']   \n",
       "...           ...         ...                             ...   \n",
       "18987        2019  9950788382                    ['Cr', 'Dr']   \n",
       "18988        2019  9950790111                    ['Cr', 'Dr']   \n",
       "18989        2019  9950790176                    ['Cr', 'Dr']   \n",
       "18990        2019  9950790623                    ['Cr', 'Dr']   \n",
       "18991        2019  9950793340                    ['Cr', 'Dr']   \n",
       "\n",
       "      DateOfAccDocEntry DateOfAccDocEntry_and_TimeOfEntry (MYT)  \\\n",
       "0            2014-01-08                     2014-01-08 20:21:18   \n",
       "1            2014-01-05                     2014-01-06 14:23:14   \n",
       "2            2014-01-06                     2014-01-06 21:30:01   \n",
       "3            2014-01-10                     2014-01-10 17:54:51   \n",
       "4            2014-01-02                     2014-01-02 19:09:35   \n",
       "...                 ...                                     ...   \n",
       "18987        2019-06-14                     2019-06-14 16:15:56   \n",
       "18988        2019-06-18                     2019-06-18 18:15:10   \n",
       "18989        2019-06-18                     2019-06-18 18:15:51   \n",
       "18990        2019-06-18                     2019-06-19 10:15:53   \n",
       "18991        2019-06-24                     2019-06-25 14:15:11   \n",
       "\n",
       "                      NoOfLineItemInAccDoc  \\\n",
       "0      ['001', '002', '003', '004', '005']   \n",
       "1                           ['001', '002']   \n",
       "2                           ['001', '002']   \n",
       "3             ['001', '002', '003', '004']   \n",
       "4                           ['001', '002']   \n",
       "...                                    ...   \n",
       "18987                       ['001', '002']   \n",
       "18988                       ['001', '002']   \n",
       "18989                       ['001', '002']   \n",
       "18990                       ['001', '002']   \n",
       "18991                       ['001', '002']   \n",
       "\n",
       "                                  RefKeyForLineItem  \\\n",
       "0      ['5821-MRT-PMO-004', None, None, None, None]   \n",
       "1                                [8500008426, None]   \n",
       "2                                [8400061160, None]   \n",
       "3                      [13012154, None, None, None]   \n",
       "4                                    [626733, None]   \n",
       "...                                             ...   \n",
       "18987                           ['190240AUT', None]   \n",
       "18988                       ['180414HPB(R1)', None]   \n",
       "18989                       ['180417HPW(R1)', None]   \n",
       "18990                       ['180416HPD(R1)', None]   \n",
       "18991                           ['190443APC', None]   \n",
       "\n",
       "                                          GL_DESCRIPTION  \\\n",
       "0      ['Accounts Receivable Control Account', 'Third...   \n",
       "1      ['Accounts Receivable Control Account', 'Third...   \n",
       "2      ['Accounts Receivable Control Account', 'Third...   \n",
       "3      ['Accounts Receivable Control Account', 'Third...   \n",
       "4      ['Accounts Receivable Control Account', 'Third...   \n",
       "...                                                  ...   \n",
       "18987  ['Accounts Receivable Control Account', 'Marke...   \n",
       "18988  ['Accounts Receivable Control Account', 'Vendo...   \n",
       "18989  ['Accounts Receivable Control Account', 'Vendo...   \n",
       "18990  ['Accounts Receivable Control Account', 'Vendo...   \n",
       "18991  ['Accounts Receivable Control Account', 'Marke...   \n",
       "\n",
       "                     Amt_localCurrencyFormatted Document Type Description  \\\n",
       "0      [3018.0, -2848.0, -284.0, 284.0, -170.0]      Billing Doc.Transfer   \n",
       "1                             [1280.0, -1280.0]      Billing Doc.Transfer   \n",
       "2                             [2128.0, -2128.0]      Billing Doc.Transfer   \n",
       "3                  [201.0, -67.0, -67.0, -67.0]      Billing Doc.Transfer   \n",
       "4                                 [66.0, -66.0]      Billing Doc.Transfer   \n",
       "...                                         ...                       ...   \n",
       "18987                             [-20.0, 20.0]      Bill Doc.Tr - Cr Mem   \n",
       "18988                           [-120.0, 120.0]      Bill Doc.Tr - Cr Mem   \n",
       "18989                           [-150.0, 150.0]      Bill Doc.Tr - Cr Mem   \n",
       "18990                         [-1700.0, 1700.0]      Bill Doc.Tr - Cr Mem   \n",
       "18991                         [-4716.0, 4716.0]      Bill Doc.Tr - Cr Mem   \n",
       "\n",
       "       ... Dr_Asset - G\\L Account Dr_Cost of Goods Sold (COGS) - G\\L Account  \\\n",
       "0      ...                    0.0                                        0.0   \n",
       "1      ...                    0.0                                        0.0   \n",
       "2      ...                    0.0                                        0.0   \n",
       "3      ...                    0.0                                        0.0   \n",
       "4      ...                    0.0                                        0.0   \n",
       "...    ...                    ...                                        ...   \n",
       "18987  ...                    0.0                                        0.0   \n",
       "18988  ...                    0.0                                        0.0   \n",
       "18989  ...                    0.0                                        0.0   \n",
       "18990  ...                    0.0                                        0.0   \n",
       "18991  ...                    0.0                                        0.0   \n",
       "\n",
       "      Dr_Liability - G\\L Account  Dr_Other Costs - G\\L Account  \\\n",
       "0                            0.0                           0.0   \n",
       "1                            0.0                           0.0   \n",
       "2                            0.0                           0.0   \n",
       "3                            0.0                           0.0   \n",
       "4                            0.0                           0.0   \n",
       "...                          ...                           ...   \n",
       "18987                       20.0                           0.0   \n",
       "18988                      120.0                           0.0   \n",
       "18989                      150.0                           0.0   \n",
       "18990                     1700.0                           0.0   \n",
       "18991                     4716.0                           0.0   \n",
       "\n",
       "      Dr_Other Revenue - G\\L Account Dr_Revenue - G\\L Account Revenue  \\\n",
       "0                                0.0                    284.0  3018.0   \n",
       "1                                0.0                      0.0  1280.0   \n",
       "2                                0.0                      0.0  2128.0   \n",
       "3                                0.0                      0.0   201.0   \n",
       "4                                0.0                      0.0    66.0   \n",
       "...                              ...                      ...     ...   \n",
       "18987                            0.0                      0.0     0.0   \n",
       "18988                            0.0                      0.0     0.0   \n",
       "18989                            0.0                      0.0     0.0   \n",
       "18990                            0.0                      0.0     0.0   \n",
       "18991                            0.0                      0.0     0.0   \n",
       "\n",
       "      Amt_DocCurrency_NoOfTrailingZeroes_flag EndCheck OtherCheck  \n",
       "0                                           1        0          1  \n",
       "1                                           1        0          0  \n",
       "2                                           0        0          1  \n",
       "3                                           0        0          0  \n",
       "4                                           0        0          1  \n",
       "...                                       ...      ...        ...  \n",
       "18987                                       1        0          0  \n",
       "18988                                       1        0          0  \n",
       "18989                                       1        0          0  \n",
       "18990                                       1        0          0  \n",
       "18991                                       0        1          0  \n",
       "\n",
       "[18992 rows x 67 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mark_any_one(df, cols, new_col_name='has_one'):\n",
    "    df[new_col_name] = df[cols].apply(lambda row: int(1 in row.values), axis=1)\n",
    "    return df\n",
    "\n",
    "merge_cols = ['IND_MonthEnd', 'IND_QuarterEnd', 'IND_YearEnd']\n",
    "mark_any_one(df_result, merge_cols, new_col_name='EndCheck')\n",
    "\n",
    "merge_cols = ['IND_Weekend', 'IND_PublicHol', 'IND_OutsideWorkHours']\n",
    "mark_any_one(df_result, merge_cols, new_col_name='OtherCheck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IND_Weekend</th>\n",
       "      <th>IND_PublicHol</th>\n",
       "      <th>IND_OutsideWorkHours</th>\n",
       "      <th>OtherCheck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18940</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18954</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18966</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3157 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       IND_Weekend  IND_PublicHol  IND_OutsideWorkHours  OtherCheck\n",
       "0                0              0                     1           1\n",
       "2                0              0                     1           1\n",
       "4                0              0                     1           1\n",
       "20               0              0                     1           1\n",
       "28               0              0                     1           1\n",
       "...            ...            ...                   ...         ...\n",
       "18940            1              0                     0           1\n",
       "18954            0              0                     1           1\n",
       "18966            0              0                     1           1\n",
       "18973            0              0                     1           1\n",
       "18976            0              0                     1           1\n",
       "\n",
       "[3157 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['IND_Weekend', 'IND_PublicHol', 'IND_OutsideWorkHours','OtherCheck']\n",
    "df_result[df_result[cols].eq(1).any(axis=1)][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IND_MonthEnd</th>\n",
       "      <th>IND_QuarterEnd</th>\n",
       "      <th>IND_YearEnd</th>\n",
       "      <th>EndCheck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18959</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18960</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18961</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18975</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18991</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3959 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       IND_MonthEnd  IND_QuarterEnd  IND_YearEnd  EndCheck\n",
       "412               0               0            1         1\n",
       "447               0               0            1         1\n",
       "547               0               0            1         1\n",
       "585               1               0            0         1\n",
       "588               0               0            1         1\n",
       "...             ...             ...          ...       ...\n",
       "18959             0               0            1         1\n",
       "18960             0               1            1         1\n",
       "18961             0               1            1         1\n",
       "18975             1               0            0         1\n",
       "18991             0               1            0         1\n",
       "\n",
       "[3959 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['IND_MonthEnd', 'IND_QuarterEnd', 'IND_YearEnd','EndCheck']\n",
    "df_result[df_result[cols].eq(1).any(axis=1)][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding (1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_list_column_distinct_values(df, column_list):\n",
    "    \"\"\"\n",
    "    For each column in column_list, extract distinct non-NULL values from list entries,\n",
    "    and create binary indicator columns for each distinct value.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    column_list (list): List of column names to process\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Original dataframe with new binary columns for each distinct value\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original dataframe\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    for col in column_list:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Warning: Column '{col}' not found in dataframe.\")\n",
    "            continue\n",
    "            \n",
    "        # To store all distinct non-NULL values across all rows\n",
    "        distinct_values = set()\n",
    "        \n",
    "        # First pass: collect all distinct non-NULL values\n",
    "        for idx, row in df.iterrows():\n",
    "            cell_value = row[col]\n",
    "            \n",
    "            # Handle cases where the cell might not be a list\n",
    "            if isinstance(cell_value, (list, tuple)):\n",
    "                # Filter out NULL/None/NaN values\n",
    "                non_null_values = [val for val in cell_value \n",
    "                                 if val is not None and not (isinstance(val, float) and pd.isna(val))]\n",
    "                distinct_values.update(non_null_values)\n",
    "        \n",
    "        # Sort for consistent column ordering\n",
    "        distinct_values = sorted(distinct_values)\n",
    "        \n",
    "        # If no distinct values found (all NULL), still create columns with 0s\n",
    "        if not distinct_values:\n",
    "            distinct_values = []\n",
    "        \n",
    "        # Second pass: create binary indicator columns\n",
    "        for value in distinct_values:\n",
    "            new_col_name = f\"{col}_{value}\"\n",
    "            indicator_values = []\n",
    "            \n",
    "            for idx, row in df.iterrows():\n",
    "                cell_value = row[col]\n",
    "                found = 0\n",
    "                \n",
    "                if isinstance(cell_value, (list, tuple)):\n",
    "                    # Check if the value exists in the list (and list is not all NULL)\n",
    "                    non_null_values = [val for val in cell_value \n",
    "                                     if val is not None and not (isinstance(val, float) and pd.isna(val))]\n",
    "                    \n",
    "                    if value in non_null_values:\n",
    "                        found = 1\n",
    "                    # If all values in list are NULL, keep 0 (already set)\n",
    "                \n",
    "                indicator_values.append(found)\n",
    "            \n",
    "            result_df[new_col_name] = indicator_values\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_cols = ['PostingKey', 'TermsOfPayment', 'Plant', 'isLineItemAutomaticallyCreated', 'PaymentMethod']\n",
    "df_result = expand_list_column_distinct_values(df_result, one_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_encode = [\n",
    "'Document Type Description',\n",
    "'IsDocReversalOrReversedDoc',\n",
    "'Username Type']\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_array = encoder.fit_transform(df_result[to_encode])\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(to_encode))\n",
    "\n",
    "# Combine with original DataFrame\n",
    "df_result = pd.concat([df_result, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "26\n",
      "['Cr_Asset - Customer', 'Cr_Asset - G\\\\L Account', 'Cr_Cost of Goods Sold (COGS) - G\\\\L Account', 'Cr_Liability - G\\\\L Account', 'Cr_Other Costs - G\\\\L Account', 'Cr_Other Revenue - G\\\\L Account', 'Cr_Revenue - G\\\\L Account', 'Dr_Asset - Customer', 'Dr_Asset - G\\\\L Account', 'Dr_Cost of Goods Sold (COGS) - G\\\\L Account', 'Dr_Liability - G\\\\L Account', 'Dr_Other Costs - G\\\\L Account', 'Dr_Other Revenue - G\\\\L Account', 'Dr_Revenue - G\\\\L Account', 'Revenue', 'Amt_DocCurrency_NoOfTrailingZeroes_flag', 'EndCheck', 'OtherCheck', 'Document Type Description_Bill Doc.Tr - Cr Mem', 'Document Type Description_Bill Doc.Tr - Dr Mem', 'Document Type Description_Billing Doc.Transfer', 'IsDocReversalOrReversedDoc_1.0', 'IsDocReversalOrReversedDoc_2.0', 'IsDocReversalOrReversedDoc_nan', 'Username Type_MY', 'Username Type_System']\n"
     ]
    }
   ],
   "source": [
    "non_features = [\n",
    "'Dr_Cr',\n",
    "'FiscalYear', \n",
    "'AccDocNo', \n",
    "'DateOfAccDocEntry', \n",
    "'DateOfAccDocEntry_and_TimeOfEntry (MYT)',\n",
    "'NoOfLineItemInAccDoc',\n",
    "'Customer PO Number', \n",
    "'IS Rep',\n",
    "'Sold-To Id',\n",
    "'IND_MonthEnd',\n",
    "'IND_QuarterEnd',\n",
    "'IND_YearEnd',\n",
    "'IND_Weekend',\n",
    "'IND_PublicHol',\n",
    "'IND_OutsideWorkHours',\n",
    "'SpecialGLIndicator',\n",
    "'hasSubsequentDrCrMemo',\n",
    "'IdOfLineItem',\n",
    "'TransactionCode',\n",
    "'Quantity',\n",
    "'labelled_TransactionCode',\n",
    "'labelled_Document Type Description',\n",
    "'labelled_Username Type',\n",
    "'IsDocReversalOrReversedDoc',\n",
    "]\n",
    "\n",
    "# Get boolean cols\n",
    "bool_cols = df_result.select_dtypes(include='bool').columns.tolist()\n",
    "print(bool_cols)\n",
    "\n",
    "# Convert bool cols to int\n",
    "df_result[bool_cols] = df_result[bool_cols].astype(int)\n",
    "\n",
    "# Get numerical feature columns\n",
    "def get_num_cols(df):\n",
    "    numerical_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "    numerical_cols = [item for item in numerical_cols if item not in non_features]\n",
    "\n",
    "    return numerical_cols\n",
    "\n",
    "num_cols = get_num_cols(df_result)\n",
    "print(len(num_cols))\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cr_Asset - Customer',\n",
       " 'Cr_Asset - G\\\\L Account',\n",
       " 'Cr_Cost of Goods Sold (COGS) - G\\\\L Account',\n",
       " 'Cr_Liability - G\\\\L Account',\n",
       " 'Cr_Other Costs - G\\\\L Account',\n",
       " 'Cr_Other Revenue - G\\\\L Account',\n",
       " 'Cr_Revenue - G\\\\L Account',\n",
       " 'Dr_Asset - Customer',\n",
       " 'Dr_Asset - G\\\\L Account',\n",
       " 'Dr_Cost of Goods Sold (COGS) - G\\\\L Account',\n",
       " 'Dr_Liability - G\\\\L Account',\n",
       " 'Dr_Other Costs - G\\\\L Account',\n",
       " 'Dr_Other Revenue - G\\\\L Account',\n",
       " 'Dr_Revenue - G\\\\L Account',\n",
       " 'Revenue',\n",
       " 'Amt_DocCurrency_NoOfTrailingZeroes_flag',\n",
       " 'EndCheck',\n",
       " 'OtherCheck',\n",
       " 'Document Type Description_Bill Doc.Tr - Cr Mem',\n",
       " 'Document Type Description_Bill Doc.Tr - Dr Mem',\n",
       " 'Document Type Description_Billing Doc.Transfer',\n",
       " 'IsDocReversalOrReversedDoc_1.0',\n",
       " 'IsDocReversalOrReversedDoc_2.0',\n",
       " 'IsDocReversalOrReversedDoc_nan',\n",
       " 'Username Type_MY',\n",
       " 'Username Type_System']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select relevant features for anomaly detection\n",
    "df_numeric = df_result[num_cols].copy()\n",
    "df_numeric.columns.tolist()\n",
    "\n",
    "# Preprocess the data (important for density-based methods)\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values: 0\n",
      "Number of Inf values: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "print(\"Number of NaN values:\", np.isnan(df_numeric).sum().sum())\n",
    "\n",
    "# Check for Infs\n",
    "print(\"Number of Inf values:\", np.isinf(df_numeric).sum().sum())\n",
    "\n",
    "# Find columns with at least one NaN\n",
    "nan_columns = df_numeric.columns[df_numeric.isna().any()].tolist()\n",
    "# print(\"Columns with NaN values:\", nan_columns)\n",
    "\n",
    "# Get unique non-null values from each NaN column\n",
    "unique_data_in_nan_columns = {\n",
    "    col: df_numeric[col].dropna().unique().tolist()\n",
    "    for col in nan_columns\n",
    "}\n",
    "\n",
    "# Display the results\n",
    "for col, unique_vals in unique_data_in_nan_columns.items():\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Unique values (excluding NaN): {unique_vals}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_col = 'K_cluster'\n",
    "\n",
    "cols_to_fill = [col for col in df_numeric.columns if col != exclude_col]\n",
    "df_numeric[cols_to_fill] = df_numeric[cols_to_fill].fillna(0)\n",
    "\n",
    "# Check for NaNs\n",
    "print(\"Number of NaN values:\", np.isnan(df_numeric).sum().sum())\n",
    "\n",
    "# Check for Infs\n",
    "print(\"Number of Inf values:\", np.isinf(df_numeric).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = False\n",
    "if 'K_cluster' in df_numeric.columns:\n",
    "    df_num = df_numeric.drop('K_cluster', axis=1)\n",
    "    df_num.info()\n",
    "    check = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Standardize the numeric data\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(df_num)\n",
    "\n",
    "# Step 2: Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Adjust n_components as needed\n",
    "if check:\n",
    "    to_use = df_num\n",
    "else:\n",
    "    to_use = df_numeric\n",
    "\n",
    "X_pca = pca.fit_transform(to_use)\n",
    "\n",
    "# Step 3: Reconstruct from PCA space\n",
    "X_reconstructed = pca.inverse_transform(X_pca)\n",
    "\n",
    "# Step 4: Compute reconstruction error\n",
    "reconstruction_errors = np.mean((to_use - X_reconstructed) ** 2, axis=1)\n",
    "\n",
    "# Step 5: Set threshold (e.g., 99th percentile)\n",
    "threshold = np.percentile(reconstruction_errors, 99)\n",
    "anomalies_mask = reconstruction_errors > threshold\n",
    "\n",
    "# Step 6: Add info back to original DataFrame\n",
    "all_outliers = sales_df.copy()  # Work on a copy\n",
    "\n",
    "# Add reconstruction error and global anomaly flag\n",
    "all_outliers['reconstruction_error'] = reconstruction_errors\n",
    "all_outliers['is_anomaly'] = anomalies_mask.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FiscalYear</th>\n",
       "      <th>AccDocNo</th>\n",
       "      <th>Dr_Cr</th>\n",
       "      <th>DateOfAccDocEntry</th>\n",
       "      <th>DateOfAccDocEntry_and_TimeOfEntry (MYT)</th>\n",
       "      <th>NoOfLineItemInAccDoc</th>\n",
       "      <th>RefKeyForLineItem</th>\n",
       "      <th>GL_DESCRIPTION</th>\n",
       "      <th>Amt_localCurrencyFormatted</th>\n",
       "      <th>Document Type Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Dr_Asset - Customer</th>\n",
       "      <th>Dr_Asset - G\\L Account</th>\n",
       "      <th>Dr_Cost of Goods Sold (COGS) - G\\L Account</th>\n",
       "      <th>Dr_Liability - G\\L Account</th>\n",
       "      <th>Dr_Other Costs - G\\L Account</th>\n",
       "      <th>Dr_Other Revenue - G\\L Account</th>\n",
       "      <th>Dr_Revenue - G\\L Account</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2014</td>\n",
       "      <td>9900734855</td>\n",
       "      <td>['Dr', 'Cr', 'Cr', 'Dr']</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>2014-01-07 12:31:50</td>\n",
       "      <td>['001', '002', '003', '004']</td>\n",
       "      <td>['00729-INSTALLATION-T', None, None, None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Warra...</td>\n",
       "      <td>[134815.0, -134815.0, -129000.0, 129000.0]</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>134815.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>134815.0</td>\n",
       "      <td>1.816467e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2014</td>\n",
       "      <td>9900953449</td>\n",
       "      <td>['Dr', 'Cr', 'Cr', 'Dr', 'Cr', 'Cr', 'Dr', 'Cr...</td>\n",
       "      <td>2014-02-25</td>\n",
       "      <td>2014-02-25 19:52:17</td>\n",
       "      <td>['001', '002', '003', '004', '005', '006', '00...</td>\n",
       "      <td>['P14020043*-CL', None, None, None, None, None...</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[346702.0, -280750.0, -1.27, 1.27, -11638.0, -...</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>346702.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1862.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>346702.0</td>\n",
       "      <td>2.005159e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2014</td>\n",
       "      <td>9900974511</td>\n",
       "      <td>['Dr', 'Cr', 'Cr', 'Dr', 'Cr', 'Dr', 'Cr', 'Cr...</td>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>2014-02-28 14:21:55</td>\n",
       "      <td>['001', '002', '003', '004', '005', '006', '00...</td>\n",
       "      <td>['P.O-AUG13/INGRAM 203', None, None, None, Non...</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[339515.0, -333305.0, -1.1, 1.1, -1.1, 1.1, -6...</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>339515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>899.23</td>\n",
       "      <td>339515.0</td>\n",
       "      <td>1.911362e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>2014</td>\n",
       "      <td>9901019606</td>\n",
       "      <td>['Dr', 'Cr', 'Cr', 'Dr']</td>\n",
       "      <td>2014-03-10</td>\n",
       "      <td>2014-03-11 11:30:34</td>\n",
       "      <td>['001', '002', '003', '004']</td>\n",
       "      <td>['PO-11022*', None, None, None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[1148400.0, -1148400.0, -1119073.87, 1119073.87]</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>1148400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1119073.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1148400.0</td>\n",
       "      <td>2.483110e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2014</td>\n",
       "      <td>9901049063</td>\n",
       "      <td>['Dr', 'Cr', 'Cr']</td>\n",
       "      <td>2014-03-16</td>\n",
       "      <td>2014-03-17 10:37:46</td>\n",
       "      <td>['001', '002', '003']</td>\n",
       "      <td>['IERAT/2013/12/563*AK', None, None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[645655.9, -645655.88, -0.02]</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>645655.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>645655.9</td>\n",
       "      <td>7.059300e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18669</th>\n",
       "      <td>2019</td>\n",
       "      <td>9912343837</td>\n",
       "      <td>['Dr', 'Cr', 'Cr', 'Cr']</td>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>2019-06-10 15:26:19</td>\n",
       "      <td>['001', '002', '003', '004']</td>\n",
       "      <td>['MYL19003', None, None, None]</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[357480.0, -301920.0, -2880.0, -52680.0]</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>357480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>357480.0</td>\n",
       "      <td>2.134030e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18808</th>\n",
       "      <td>2019</td>\n",
       "      <td>9912432284</td>\n",
       "      <td>['Dr', 'Cr', 'Cr', 'Cr', 'Cr', 'Cr', 'Cr', 'Cr']</td>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>2019-06-24 17:43:41</td>\n",
       "      <td>['001', '002', '003', '004', '005', '006', '00...</td>\n",
       "      <td>['MYL19003', None, None, None, None, None, Non...</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[1487792.0, -1182520.0, -11280.0, -68208.0, -6...</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>1487792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1487792.0</td>\n",
       "      <td>3.785121e+10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18865</th>\n",
       "      <td>2019</td>\n",
       "      <td>9912461742</td>\n",
       "      <td>['Dr', 'Cr', 'Cr', 'Dr', 'Cr', 'Dr', 'Cr', 'Dr...</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>2019-06-29 13:02:25</td>\n",
       "      <td>['001', '002', '003', '004', '005', '006', '00...</td>\n",
       "      <td>['R0219-018', None, None, None, None, None, No...</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Third...</td>\n",
       "      <td>[349306.0, -29451.69, -0.02, 0.02, -0.02, 0.02...</td>\n",
       "      <td>Billing Doc.Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>349306.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>349306.0</td>\n",
       "      <td>2.036057e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18942</th>\n",
       "      <td>2019</td>\n",
       "      <td>9950689721</td>\n",
       "      <td>['Cr', 'Dr', 'Cr', 'Dr', 'Cr', 'Dr', 'Dr', 'Cr...</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>2018-12-31 10:21:18</td>\n",
       "      <td>['001', '002', '003', '004', '005', '006', '00...</td>\n",
       "      <td>['CN-8580008875', None, None, None, None, None...</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Sales...</td>\n",
       "      <td>[-177570.0, 36946.8, -36946.8, 35099.13, -3509...</td>\n",
       "      <td>Bill Doc.Tr - Cr Mem</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>167536.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278161.25</td>\n",
       "      <td>-177570.0</td>\n",
       "      <td>6.263341e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18943</th>\n",
       "      <td>2019</td>\n",
       "      <td>9950692726</td>\n",
       "      <td>['Cr', 'Dr', 'Dr', 'Cr', 'Dr', 'Cr', 'Dr', 'Cr...</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>2018-12-31 10:21:25</td>\n",
       "      <td>['001', '002', '003', '004', '005', '006', '00...</td>\n",
       "      <td>['CN-8580008882', None, None, None, None, None...</td>\n",
       "      <td>['Accounts Receivable Control Account', 'Sales...</td>\n",
       "      <td>[-226475.0, 34000.0, 10922.0, -10922.0, 22986....</td>\n",
       "      <td>Bill Doc.Tr - Cr Mem</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>215609.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353482.18</td>\n",
       "      <td>-226475.0</td>\n",
       "      <td>1.021779e+10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FiscalYear    AccDocNo  \\\n",
       "87           2014  9900734855   \n",
       "574          2014  9900953449   \n",
       "608          2014  9900974511   \n",
       "699          2014  9901019606   \n",
       "764          2014  9901049063   \n",
       "...           ...         ...   \n",
       "18669        2019  9912343837   \n",
       "18808        2019  9912432284   \n",
       "18865        2019  9912461742   \n",
       "18942        2019  9950689721   \n",
       "18943        2019  9950692726   \n",
       "\n",
       "                                                   Dr_Cr DateOfAccDocEntry  \\\n",
       "87                              ['Dr', 'Cr', 'Cr', 'Dr']        2014-01-06   \n",
       "574    ['Dr', 'Cr', 'Cr', 'Dr', 'Cr', 'Cr', 'Dr', 'Cr...        2014-02-25   \n",
       "608    ['Dr', 'Cr', 'Cr', 'Dr', 'Cr', 'Dr', 'Cr', 'Cr...        2014-02-27   \n",
       "699                             ['Dr', 'Cr', 'Cr', 'Dr']        2014-03-10   \n",
       "764                                   ['Dr', 'Cr', 'Cr']        2014-03-16   \n",
       "...                                                  ...               ...   \n",
       "18669                           ['Dr', 'Cr', 'Cr', 'Cr']        2019-06-09   \n",
       "18808   ['Dr', 'Cr', 'Cr', 'Cr', 'Cr', 'Cr', 'Cr', 'Cr']        2019-06-24   \n",
       "18865  ['Dr', 'Cr', 'Cr', 'Dr', 'Cr', 'Dr', 'Cr', 'Dr...        2019-06-28   \n",
       "18942  ['Cr', 'Dr', 'Cr', 'Dr', 'Cr', 'Dr', 'Dr', 'Cr...        2018-12-30   \n",
       "18943  ['Cr', 'Dr', 'Dr', 'Cr', 'Dr', 'Cr', 'Dr', 'Cr...        2018-12-30   \n",
       "\n",
       "      DateOfAccDocEntry_and_TimeOfEntry (MYT)  \\\n",
       "87                        2014-01-07 12:31:50   \n",
       "574                       2014-02-25 19:52:17   \n",
       "608                       2014-02-28 14:21:55   \n",
       "699                       2014-03-11 11:30:34   \n",
       "764                       2014-03-17 10:37:46   \n",
       "...                                       ...   \n",
       "18669                     2019-06-10 15:26:19   \n",
       "18808                     2019-06-24 17:43:41   \n",
       "18865                     2019-06-29 13:02:25   \n",
       "18942                     2018-12-31 10:21:18   \n",
       "18943                     2018-12-31 10:21:25   \n",
       "\n",
       "                                    NoOfLineItemInAccDoc  \\\n",
       "87                          ['001', '002', '003', '004']   \n",
       "574    ['001', '002', '003', '004', '005', '006', '00...   \n",
       "608    ['001', '002', '003', '004', '005', '006', '00...   \n",
       "699                         ['001', '002', '003', '004']   \n",
       "764                                ['001', '002', '003']   \n",
       "...                                                  ...   \n",
       "18669                       ['001', '002', '003', '004']   \n",
       "18808  ['001', '002', '003', '004', '005', '006', '00...   \n",
       "18865  ['001', '002', '003', '004', '005', '006', '00...   \n",
       "18942  ['001', '002', '003', '004', '005', '006', '00...   \n",
       "18943  ['001', '002', '003', '004', '005', '006', '00...   \n",
       "\n",
       "                                       RefKeyForLineItem  \\\n",
       "87            ['00729-INSTALLATION-T', None, None, None]   \n",
       "574    ['P14020043*-CL', None, None, None, None, None...   \n",
       "608    ['P.O-AUG13/INGRAM 203', None, None, None, Non...   \n",
       "699                      ['PO-11022*', None, None, None]   \n",
       "764                 ['IERAT/2013/12/563*AK', None, None]   \n",
       "...                                                  ...   \n",
       "18669                     ['MYL19003', None, None, None]   \n",
       "18808  ['MYL19003', None, None, None, None, None, Non...   \n",
       "18865  ['R0219-018', None, None, None, None, None, No...   \n",
       "18942  ['CN-8580008875', None, None, None, None, None...   \n",
       "18943  ['CN-8580008882', None, None, None, None, None...   \n",
       "\n",
       "                                          GL_DESCRIPTION  \\\n",
       "87     ['Accounts Receivable Control Account', 'Warra...   \n",
       "574    ['Accounts Receivable Control Account', 'Third...   \n",
       "608    ['Accounts Receivable Control Account', 'Third...   \n",
       "699    ['Accounts Receivable Control Account', 'Third...   \n",
       "764    ['Accounts Receivable Control Account', 'Third...   \n",
       "...                                                  ...   \n",
       "18669  ['Accounts Receivable Control Account', 'Third...   \n",
       "18808  ['Accounts Receivable Control Account', 'Third...   \n",
       "18865  ['Accounts Receivable Control Account', 'Third...   \n",
       "18942  ['Accounts Receivable Control Account', 'Sales...   \n",
       "18943  ['Accounts Receivable Control Account', 'Sales...   \n",
       "\n",
       "                              Amt_localCurrencyFormatted  \\\n",
       "87            [134815.0, -134815.0, -129000.0, 129000.0]   \n",
       "574    [346702.0, -280750.0, -1.27, 1.27, -11638.0, -...   \n",
       "608    [339515.0, -333305.0, -1.1, 1.1, -1.1, 1.1, -6...   \n",
       "699     [1148400.0, -1148400.0, -1119073.87, 1119073.87]   \n",
       "764                        [645655.9, -645655.88, -0.02]   \n",
       "...                                                  ...   \n",
       "18669           [357480.0, -301920.0, -2880.0, -52680.0]   \n",
       "18808  [1487792.0, -1182520.0, -11280.0, -68208.0, -6...   \n",
       "18865  [349306.0, -29451.69, -0.02, 0.02, -0.02, 0.02...   \n",
       "18942  [-177570.0, 36946.8, -36946.8, 35099.13, -3509...   \n",
       "18943  [-226475.0, 34000.0, 10922.0, -10922.0, 22986....   \n",
       "\n",
       "      Document Type Description  ... Dr_Asset - Customer  \\\n",
       "87         Billing Doc.Transfer  ...            134815.0   \n",
       "574        Billing Doc.Transfer  ...            346702.0   \n",
       "608        Billing Doc.Transfer  ...            339515.0   \n",
       "699        Billing Doc.Transfer  ...           1148400.0   \n",
       "764        Billing Doc.Transfer  ...            645655.9   \n",
       "...                         ...  ...                 ...   \n",
       "18669      Billing Doc.Transfer  ...            357480.0   \n",
       "18808      Billing Doc.Transfer  ...           1487792.0   \n",
       "18865      Billing Doc.Transfer  ...            349306.0   \n",
       "18942      Bill Doc.Tr - Cr Mem  ...                 0.0   \n",
       "18943      Bill Doc.Tr - Cr Mem  ...                 0.0   \n",
       "\n",
       "      Dr_Asset - G\\L Account Dr_Cost of Goods Sold (COGS) - G\\L Account  \\\n",
       "87                       0.0                                       0.00   \n",
       "574                      0.0                                       0.00   \n",
       "608                      0.0                                       0.00   \n",
       "699                      0.0                                 1119073.87   \n",
       "764                      0.0                                       0.00   \n",
       "...                      ...                                        ...   \n",
       "18669                    0.0                                       0.00   \n",
       "18808                    0.0                                       0.00   \n",
       "18865                    0.0                                       0.00   \n",
       "18942                    0.0                                       0.00   \n",
       "18943                    0.0                                       0.00   \n",
       "\n",
       "       Dr_Liability - G\\L Account Dr_Other Costs - G\\L Account  \\\n",
       "87                           0.00                     129000.0   \n",
       "574                       1862.50                          0.0   \n",
       "608                          0.00                          0.0   \n",
       "699                          0.00                          0.0   \n",
       "764                          0.00                          0.0   \n",
       "...                           ...                          ...   \n",
       "18669                        0.00                          0.0   \n",
       "18808                        0.00                          0.0   \n",
       "18865                        0.00                          0.0   \n",
       "18942                   167536.97                          0.0   \n",
       "18943                   215609.67                          0.0   \n",
       "\n",
       "      Dr_Other Revenue - G\\L Account Dr_Revenue - G\\L Account    Revenue  \\\n",
       "87                               0.0                     0.00   134815.0   \n",
       "574                              0.0                     1.31   346702.0   \n",
       "608                              0.0                   899.23   339515.0   \n",
       "699                              0.0                     0.00  1148400.0   \n",
       "764                              0.0                     0.00   645655.9   \n",
       "...                              ...                      ...        ...   \n",
       "18669                            0.0                     0.00   357480.0   \n",
       "18808                            0.0                     0.00  1487792.0   \n",
       "18865                            0.0                     0.18   349306.0   \n",
       "18942                            0.0                278161.25  -177570.0   \n",
       "18943                            0.0                353482.18  -226475.0   \n",
       "\n",
       "      reconstruction_error is_anomaly  \n",
       "87            1.816467e+09          1  \n",
       "574           2.005159e+09          1  \n",
       "608           1.911362e+09          1  \n",
       "699           2.483110e+09          1  \n",
       "764           7.059300e+09          1  \n",
       "...                    ...        ...  \n",
       "18669         2.134030e+09          1  \n",
       "18808         3.785121e+10          1  \n",
       "18865         2.036057e+09          1  \n",
       "18942         6.263341e+09          1  \n",
       "18943         1.021779e+10          1  \n",
       "\n",
       "[190 rows x 66 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outliers[all_outliers['is_anomaly'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "# table_name=\"anomaly_res_pca_full\"\n",
    "\n",
    "# sql_db.fn_create_new_table_from_df(table_name=table_name, df=all_outliers, auto_data_type=True)\n",
    "# res=sql_db.fn_append_df_to_table(table_name=table_name, df=all_outliers)\n",
    "# print(res)\n",
    "\n",
    "# 8 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outliers.to_excel(rf\"D:\\victoriaquek\\JE ML 2025\\Results\\siewpl_pca.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18992 entries, 0 to 18991\n",
      "Data columns (total 66 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   FiscalYear                                  18992 non-null  int64  \n",
      " 1   AccDocNo                                    18992 non-null  int64  \n",
      " 2   Dr_Cr                                       18992 non-null  object \n",
      " 3   DateOfAccDocEntry                           18992 non-null  object \n",
      " 4   DateOfAccDocEntry_and_TimeOfEntry (MYT)     18992 non-null  object \n",
      " 5   NoOfLineItemInAccDoc                        18992 non-null  object \n",
      " 6   RefKeyForLineItem                           18992 non-null  object \n",
      " 7   GL_DESCRIPTION                              18992 non-null  object \n",
      " 8   Amt_localCurrencyFormatted                  18992 non-null  object \n",
      " 9   Document Type Description                   18992 non-null  object \n",
      " 10  Quantity                                    18992 non-null  object \n",
      " 11  Username                                    18992 non-null  object \n",
      " 12  TransactionCode                             10679 non-null  object \n",
      " 13  IsDocReversalOrReversedDoc                  136 non-null    float64\n",
      " 14  IdOfLineItem                                18992 non-null  object \n",
      " 15  PostingKey                                  18992 non-null  object \n",
      " 16  isLineItemAutomaticallyCreated              18992 non-null  object \n",
      " 17  TermsOfPayment                              18992 non-null  object \n",
      " 18  CashDiscountAmountInLocalCurrency           18992 non-null  object \n",
      " 19  PaymentMethod                               18992 non-null  object \n",
      " 20  Plant                                       18992 non-null  object \n",
      " 21  hasSubsequentDrCrMemo                       18992 non-null  object \n",
      " 22  WBSElement                                  18992 non-null  object \n",
      " 23  SpecialGLIndicator                          18992 non-null  object \n",
      " 24  GL_AccType_AccountTypeDesc                  18992 non-null  object \n",
      " 25  Username Type                               18992 non-null  object \n",
      " 26  Amt_DocCurrency_NoOfTrailingZeroes          18992 non-null  object \n",
      " 27  CashDiscountPercentage                      18992 non-null  object \n",
      " 28  IND_MonthEnd                                18992 non-null  int64  \n",
      " 29  IND_QuarterEnd                              18992 non-null  int64  \n",
      " 30  IND_YearEnd                                 18992 non-null  int64  \n",
      " 31  IND_Weekend                                 18992 non-null  int64  \n",
      " 32  IND_PublicHol                               18992 non-null  int64  \n",
      " 33  IND_OutsideWorkHours                        18992 non-null  int64  \n",
      " 34  labelled_GL_AccType                         18992 non-null  object \n",
      " 35  labelled_AccountTypeDesc                    18992 non-null  object \n",
      " 36  labelled_GL_AccType_AccountTypeDesc         18992 non-null  object \n",
      " 37  labelled_GL_DESCRIPTION                     18992 non-null  object \n",
      " 38  labelled_Document Type Description          18992 non-null  int64  \n",
      " 39  labelled_Username                           18992 non-null  object \n",
      " 40  labelled_TransactionCode                    18992 non-null  int64  \n",
      " 41  labelled_IdOfLineItem                       18992 non-null  object \n",
      " 42  labelled_PostingKey                         18992 non-null  object \n",
      " 43  labelled_isLineItemAutomaticallyCreated     18992 non-null  object \n",
      " 44  labelled_TermsOfPayment                     18992 non-null  object \n",
      " 45  labelled_PaymentMethod                      18992 non-null  object \n",
      " 46  labelled_FollowOnDocType                    18992 non-null  object \n",
      " 47  labelled_Plant                              18992 non-null  object \n",
      " 48  labelled_Username Type                      18992 non-null  int64  \n",
      " 49  Cr_Asset - Customer                         18992 non-null  float64\n",
      " 50  Cr_Asset - G\\L Account                      18992 non-null  float64\n",
      " 51  Cr_Cost of Goods Sold (COGS) - G\\L Account  18992 non-null  float64\n",
      " 52  Cr_Liability - G\\L Account                  18992 non-null  float64\n",
      " 53  Cr_Other Costs - G\\L Account                18992 non-null  float64\n",
      " 54  Cr_Other Revenue - G\\L Account              18992 non-null  float64\n",
      " 55  Cr_Revenue - G\\L Account                    18992 non-null  float64\n",
      " 56  Dr_Asset - Customer                         18992 non-null  float64\n",
      " 57  Dr_Asset - G\\L Account                      18992 non-null  float64\n",
      " 58  Dr_Cost of Goods Sold (COGS) - G\\L Account  18992 non-null  float64\n",
      " 59  Dr_Liability - G\\L Account                  18992 non-null  float64\n",
      " 60  Dr_Other Costs - G\\L Account                18992 non-null  float64\n",
      " 61  Dr_Other Revenue - G\\L Account              18992 non-null  float64\n",
      " 62  Dr_Revenue - G\\L Account                    18992 non-null  float64\n",
      " 63  Revenue                                     18992 non-null  float64\n",
      " 64  reconstruction_error                        18992 non-null  float64\n",
      " 65  is_anomaly                                  18992 non-null  int64  \n",
      "dtypes: float64(17), int64(12), object(37)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "all_outliers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ZOTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Import data \n",
    "sql_db=Conn_ODBC(database=\"JE_ML_2025\")\n",
    "\n",
    "conn=sql_db.odbc_conn_db_pyodbc()\n",
    "\n",
    "sql_query=f\"SELECT * FROM [data_ishi_ZOTC_combined]\"\n",
    "zotc = sql_db.odbc_run_sql(conn, sql_query, return_result=True)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 41735 entries, 107 to 2820728\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   IS Rep              41735 non-null  object \n",
      " 1   AccDocNo            41735 non-null  float64\n",
      " 2   Sold-To Id          41735 non-null  object \n",
      " 3   Customer PO Number  41735 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "zotc_siew = zotc[zotc['IS Rep']=='SIEW PENG LAU'][['IS Rep','Invoice Number', 'Sold-To Id', 'Customer PO Number']]\n",
    "zotc_siew.rename(columns={'Invoice Number': 'AccDocNo'}, inplace=True)\n",
    "zotc_siew.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_by_accdocno_smart_flatten(df, exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Groups DataFrame by 'AccDocNo', aggregates other columns into lists,\n",
    "    and flattens to single value if all elements in the list are identical.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame with 'AccDocNo' and other columns.\n",
    "    exclude_cols : list, optional\n",
    "        Columns to exclude from grouping/aggregation.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        One row per AccDocNo, with lists only where multiple distinct values exist.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'AccDocNo' not in df.columns:\n",
    "        raise ValueError(\"Column 'AccDocNo' not found in DataFrame.\")\n",
    "    \n",
    "    # Clean: drop rows with missing AccDocNo\n",
    "    df_clean = df.dropna(subset=['AccDocNo']).copy()\n",
    "    \n",
    "    # Determine columns to process\n",
    "    cols_to_agg = df_clean.columns.tolist()\n",
    "    if exclude_cols:\n",
    "        cols_to_agg = [col for col in cols_to_agg if col not in exclude_cols]\n",
    "    \n",
    "    # Remove AccDocNo from aggregation list\n",
    "    feature_cols = [col for col in cols_to_agg if col != 'AccDocNo']\n",
    "    \n",
    "    # Define aggregation: collect all as lists\n",
    "    agg_dict = {col: list for col in feature_cols}\n",
    "    \n",
    "    # Group by AccDocNo\n",
    "    grouped = df_clean.groupby('AccDocNo', as_index=False).agg(agg_dict)\n",
    "    \n",
    "    # Define a helper function to flatten if all values are the same\n",
    "    def flatten_if_uniform(val_list):\n",
    "        if not val_list:\n",
    "            return None\n",
    "        # Get distinct values (handle unhashable like dicts/lists with fallback)\n",
    "        try:\n",
    "            distinct = set(val_list)\n",
    "            if len(distinct) == 1:\n",
    "                return val_list[0]  # return the single unique value\n",
    "            return val_list  # keep as list if multiple distinct values\n",
    "        except TypeError:\n",
    "            # Fallback for unhashable types (e.g., dicts, lists)\n",
    "            for i in range(1, len(val_list)):\n",
    "                if val_list[i] != val_list[0]:\n",
    "                    return val_list  # not uniform, keep list\n",
    "            return val_list[0]  # all equal\n",
    "        except Exception:\n",
    "            return val_list  # fallback: keep list\n",
    "\n",
    "    # Apply flattening to each column\n",
    "    for col in feature_cols:\n",
    "        grouped[col] = grouped[col].apply(flatten_if_uniform)\n",
    "    \n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19346 entries, 0 to 19345\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   AccDocNo            19346 non-null  float64\n",
      " 1   IS Rep              19346 non-null  object \n",
      " 2   Sold-To Id          19346 non-null  object \n",
      " 3   Customer PO Number  19346 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 604.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccDocNo</th>\n",
       "      <th>IS Rep</th>\n",
       "      <th>Sold-To Id</th>\n",
       "      <th>Customer PO Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.900468e+09</td>\n",
       "      <td>SIEW PENG LAU</td>\n",
       "      <td>APEX COMMUNICATIONS SDN BHD</td>\n",
       "      <td>5821-MRT-PMO-004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.900546e+09</td>\n",
       "      <td>SIEW PENG LAU</td>\n",
       "      <td>CTC GLOBAL SDN BHD</td>\n",
       "      <td>8500008426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.900556e+09</td>\n",
       "      <td>SIEW PENG LAU</td>\n",
       "      <td>CTC GLOBAL SDN BHD</td>\n",
       "      <td>8400061160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.900588e+09</td>\n",
       "      <td>SIEW PENG LAU</td>\n",
       "      <td>CD INTEGRATED SDN BHD</td>\n",
       "      <td>13012154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.900634e+09</td>\n",
       "      <td>SIEW PENG LAU</td>\n",
       "      <td>MUTIARA SMART SDN BHD</td>\n",
       "      <td>109404-BSN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.900635e+09</td>\n",
       "      <td>SIEW PENG LAU</td>\n",
       "      <td>SISTEM RKK SDN BHD</td>\n",
       "      <td>626733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AccDocNo         IS Rep                   Sold-To Id Customer PO Number\n",
       "0  9.900468e+09  SIEW PENG LAU  APEX COMMUNICATIONS SDN BHD   5821-MRT-PMO-004\n",
       "1  9.900546e+09  SIEW PENG LAU           CTC GLOBAL SDN BHD         8500008426\n",
       "2  9.900556e+09  SIEW PENG LAU           CTC GLOBAL SDN BHD         8400061160\n",
       "3  9.900588e+09  SIEW PENG LAU        CD INTEGRATED SDN BHD           13012154\n",
       "4  9.900634e+09  SIEW PENG LAU        MUTIARA SMART SDN BHD         109404-BSN\n",
       "5  9.900635e+09  SIEW PENG LAU           SISTEM RKK SDN BHD             626733"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = group_by_accdocno_smart_flatten(zotc_siew)  # example: exclude LineItem\n",
    "test.info()\n",
    "test.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge with GL\n",
    "result = pd.merge(\n",
    "    all_outliers,\n",
    "    test,\n",
    "    on='AccDocNo',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18992 entries, 0 to 18991\n",
      "Data columns (total 69 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   FiscalYear                                  18992 non-null  int64  \n",
      " 1   AccDocNo                                    18992 non-null  int64  \n",
      " 2   Dr_Cr                                       18992 non-null  object \n",
      " 3   DateOfAccDocEntry                           18992 non-null  object \n",
      " 4   DateOfAccDocEntry_and_TimeOfEntry (MYT)     18992 non-null  object \n",
      " 5   NoOfLineItemInAccDoc                        18992 non-null  object \n",
      " 6   RefKeyForLineItem                           18992 non-null  object \n",
      " 7   GL_DESCRIPTION                              18992 non-null  object \n",
      " 8   Amt_localCurrencyFormatted                  18992 non-null  object \n",
      " 9   Document Type Description                   18992 non-null  object \n",
      " 10  Quantity                                    18992 non-null  object \n",
      " 11  Username                                    18992 non-null  object \n",
      " 12  TransactionCode                             10679 non-null  object \n",
      " 13  IsDocReversalOrReversedDoc                  136 non-null    float64\n",
      " 14  IdOfLineItem                                18992 non-null  object \n",
      " 15  PostingKey                                  18992 non-null  object \n",
      " 16  isLineItemAutomaticallyCreated              18992 non-null  object \n",
      " 17  TermsOfPayment                              18992 non-null  object \n",
      " 18  CashDiscountAmountInLocalCurrency           18992 non-null  object \n",
      " 19  PaymentMethod                               18992 non-null  object \n",
      " 20  Plant                                       18992 non-null  object \n",
      " 21  hasSubsequentDrCrMemo                       18992 non-null  object \n",
      " 22  WBSElement                                  18992 non-null  object \n",
      " 23  SpecialGLIndicator                          18992 non-null  object \n",
      " 24  GL_AccType_AccountTypeDesc                  18992 non-null  object \n",
      " 25  Username Type                               18992 non-null  object \n",
      " 26  Amt_DocCurrency_NoOfTrailingZeroes          18992 non-null  object \n",
      " 27  CashDiscountPercentage                      18992 non-null  object \n",
      " 28  IND_MonthEnd                                18992 non-null  int64  \n",
      " 29  IND_QuarterEnd                              18992 non-null  int64  \n",
      " 30  IND_YearEnd                                 18992 non-null  int64  \n",
      " 31  IND_Weekend                                 18992 non-null  int64  \n",
      " 32  IND_PublicHol                               18992 non-null  int64  \n",
      " 33  IND_OutsideWorkHours                        18992 non-null  int64  \n",
      " 34  labelled_GL_AccType                         18992 non-null  object \n",
      " 35  labelled_AccountTypeDesc                    18992 non-null  object \n",
      " 36  labelled_GL_AccType_AccountTypeDesc         18992 non-null  object \n",
      " 37  labelled_GL_DESCRIPTION                     18992 non-null  object \n",
      " 38  labelled_Document Type Description          18992 non-null  int64  \n",
      " 39  labelled_Username                           18992 non-null  object \n",
      " 40  labelled_TransactionCode                    18992 non-null  int64  \n",
      " 41  labelled_IdOfLineItem                       18992 non-null  object \n",
      " 42  labelled_PostingKey                         18992 non-null  object \n",
      " 43  labelled_isLineItemAutomaticallyCreated     18992 non-null  object \n",
      " 44  labelled_TermsOfPayment                     18992 non-null  object \n",
      " 45  labelled_PaymentMethod                      18992 non-null  object \n",
      " 46  labelled_FollowOnDocType                    18992 non-null  object \n",
      " 47  labelled_Plant                              18992 non-null  object \n",
      " 48  labelled_Username Type                      18992 non-null  int64  \n",
      " 49  Cr_Asset - Customer                         18992 non-null  float64\n",
      " 50  Cr_Asset - G\\L Account                      18992 non-null  float64\n",
      " 51  Cr_Cost of Goods Sold (COGS) - G\\L Account  18992 non-null  float64\n",
      " 52  Cr_Liability - G\\L Account                  18992 non-null  float64\n",
      " 53  Cr_Other Costs - G\\L Account                18992 non-null  float64\n",
      " 54  Cr_Other Revenue - G\\L Account              18992 non-null  float64\n",
      " 55  Cr_Revenue - G\\L Account                    18992 non-null  float64\n",
      " 56  Dr_Asset - Customer                         18992 non-null  float64\n",
      " 57  Dr_Asset - G\\L Account                      18992 non-null  float64\n",
      " 58  Dr_Cost of Goods Sold (COGS) - G\\L Account  18992 non-null  float64\n",
      " 59  Dr_Liability - G\\L Account                  18992 non-null  float64\n",
      " 60  Dr_Other Costs - G\\L Account                18992 non-null  float64\n",
      " 61  Dr_Other Revenue - G\\L Account              18992 non-null  float64\n",
      " 62  Dr_Revenue - G\\L Account                    18992 non-null  float64\n",
      " 63  Revenue                                     18992 non-null  float64\n",
      " 64  reconstruction_error                        18992 non-null  float64\n",
      " 65  is_anomaly                                  18992 non-null  int64  \n",
      " 66  IS Rep                                      18992 non-null  object \n",
      " 67  Sold-To Id                                  18992 non-null  object \n",
      " 68  Customer PO Number                          18992 non-null  object \n",
      "dtypes: float64(17), int64(12), object(40)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(rf\"D:\\victoriaquek\\JE ML 2025\\Results\\siewpl_zotc_pca.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K cluster wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume sales_df is your full DataFrame, and 'K_cluster' is a column with cluster labels\n",
    "# df_numeric = only numeric columns used for PCA (must align with sales_df's rows)\n",
    "\n",
    "# Create new columns in the original DataFrame\n",
    "all_outliers = sales_df.copy()\n",
    "all_outliers['reconstruction_error'] = np.nan\n",
    "all_outliers['is_anomaly'] = 0  # Default: not an anomaly\n",
    "\n",
    "# Loop through each cluster\n",
    "for cluster_id, group in all_outliers.groupby('K_cluster'):\n",
    "    # print(f\"\\n Processing Cluster {cluster_id}\")\n",
    "    \n",
    "    # Get indices and subset of numeric features in this cluster\n",
    "    cluster_indices = group.index\n",
    "    \n",
    "    # Make sure to use only numeric features for PCA\n",
    "    group_numeric = df_numeric.loc[cluster_indices]  # Ensure alignment with sales_df\n",
    "\n",
    "    # Skip clusters with too few samples\n",
    "    if len(group_numeric) < 2:\n",
    "        print(f\"Cluster {cluster_id} has too few samples. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Step 1: Standardize\n",
    "    # scaler = StandardScaler()\n",
    "    # X_scaled = scaler.fit_transform(group_numeric)\n",
    "\n",
    "    # Step 2: Apply PCA\n",
    "    pca = PCA(n_components=0.95)  # Keep 95% variance or set n_components manually\n",
    "    X_pca = pca.fit_transform(group_numeric)\n",
    "\n",
    "    # Step 3: Reconstruct\n",
    "    X_reconstructed = pca.inverse_transform(X_pca)\n",
    "\n",
    "    # Step 4: Compute reconstruction error\n",
    "    errors = np.mean((group_numeric - X_reconstructed) ** 2, axis=1)\n",
    "\n",
    "    # Step 5: Set threshold (e.g., 99th percentile within cluster)\n",
    "    threshold = np.percentile(errors, 99)\n",
    "    local_anomalies_mask = errors > threshold\n",
    "\n",
    "    # Step 6: Map errors and anomalies back to original DataFrame\n",
    "    all_outliers.loc[cluster_indices, 'reconstruction_error'] = errors\n",
    "    all_outliers.loc[cluster_indices[local_anomalies_mask], 'is_anomaly'] = 1\n",
    "\n",
    "    # Optional: Print stats\n",
    "    print(f\"Cluster {cluster_id}: {local_anomalies_mask.sum()} anomalies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outliers[all_outliers['is_anomaly'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outliers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "# table_name=\"anomaly_res_pca_k\"\n",
    "\n",
    "# sql_db.fn_create_new_table_from_df(table_name=table_name, df=all_outliers, auto_data_type=True)\n",
    "# res=sql_db.fn_append_df_to_table(table_name=table_name, df=all_outliers)\n",
    "# print(res)\n",
    "\n",
    "# 8 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual + K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df_result[num_cols].copy()\n",
    "df_numeric.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual = df_numeric[df_numeric['K_cluster'].isna()]\n",
    "df_numeric[df_numeric['K_cluster'].isna()]\n",
    "df_k_means = df_numeric[df_numeric['K_cluster'].notna()]\n",
    "df_k_means.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning df_manual\n",
    "# Apply fillna with 0 to all except column exclude_col (df_manual)\n",
    "exclude_col = 'K_cluster'\n",
    "\n",
    "cols_to_fill = [col for col in df_manual.columns if col != exclude_col]\n",
    "df_manual[cols_to_fill] = df_manual[cols_to_fill].fillna(0)\n",
    "\n",
    "# Remove K_cluster from manual feature df\n",
    "if 'K_cluster' in df_manual:\n",
    "    print('True')\n",
    "    df_manual = df_manual.drop('K_cluster', axis=1)\n",
    "    print('Removed')\n",
    "\n",
    "# Check for NaNs\n",
    "print(\"Number of NaN values:\", np.isnan(df_manual).sum().sum())\n",
    "\n",
    "# Check for Infs\n",
    "print(\"Number of Inf values:\", np.isinf(df_manual).sum().sum())\n",
    "df_manual.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fillna with 0 to all except column exclude_col (df_k_means)\n",
    "exclude_col = 'K_cluster'\n",
    "\n",
    "cols_to_fill = [col for col in df_k_means.columns if col != exclude_col]\n",
    "df_k_means[cols_to_fill] = df_k_means[cols_to_fill].fillna(0)\n",
    "\n",
    "if 'Cluster_ID' in df_k_means:\n",
    "    print('True')\n",
    "    df_k_means = df_k_means.drop('Cluster_ID', axis=1)\n",
    "    print('Removed')\n",
    "    \n",
    "# Check for NaNs\n",
    "print(\"Number of NaN values:\", np.isnan(df_k_means).sum().sum())\n",
    "\n",
    "# Check for Infs\n",
    "print(\"Number of Inf values:\", np.isinf(df_k_means).sum().sum())\n",
    "df_k_means.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_local_anomalies_with_pca(\n",
    "    df_subset,\n",
    "    group_col,\n",
    "    n_components=0.95,\n",
    "    threshold_percentile=99\n",
    "):\n",
    "    \"\"\"\n",
    "    Detects local anomalies within each group using PCA reconstruction error.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_subset (pd.DataFrame): Subset of original DataFrame with numeric features and group column.\n",
    "    - group_col (str): Column name indicating the group (e.g., 'K_cluster').\n",
    "    - n_components (int or float): Number of components or variance ratio for PCA.\n",
    "    - threshold_percentile (float): Percentile used to define anomaly threshold.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Copy of df_subset with added columns:\n",
    "        - 'reconstruction_error'\n",
    "        - 'is_anomaly'\n",
    "    \"\"\"\n",
    "    result_df = df_subset.copy()\n",
    "\n",
    "    # Save original feature columns before adding new ones\n",
    "    feature_cols = [col for col in result_df.columns if col != group_col]\n",
    "\n",
    "    result_df['reconstruction_error'] = np.nan\n",
    "    result_df['is_anomaly'] = 0  # Default: not an anomaly\n",
    "\n",
    "    # Make sure group_col is included in df_subset\n",
    "    if group_col not in result_df.columns:\n",
    "        raise ValueError(f\"Column '{group_col}' not found in input DataFrame.\")\n",
    "\n",
    "    for group_id, group_data in result_df.groupby(group_col):\n",
    "        # print(f\"\\n🧩 Processing Group {group_id}\")\n",
    "        \n",
    "        # Skip clusters with too few samples\n",
    "        if len(group_data) < 2:\n",
    "            print(f\"Group {group_id} has too few samples. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Extract just the numeric features (excluding group_col)\n",
    "        input = group_data[feature_cols]\n",
    "\n",
    "        # Step 1: Standardize\n",
    "        # scaler = StandardScaler()\n",
    "        # X_scaled = scaler.fit_transform(input)\n",
    "\n",
    "        # Step 2: Apply PCA\n",
    "        pca = PCA(n_components=0.95)  # Keep 95% variance by default\n",
    "        X_pca = pca.fit_transform(input)\n",
    "\n",
    "        # Step 3: Reconstruct\n",
    "        X_reconstructed = pca.inverse_transform(X_pca)\n",
    "\n",
    "        # Step 4: Compute reconstruction error\n",
    "        errors = np.mean((input - X_reconstructed) ** 2, axis=1)\n",
    "\n",
    "        # Step 5: Set threshold\n",
    "        threshold = np.percentile(errors, threshold_percentile)\n",
    "        local_anomalies_mask = errors > threshold\n",
    "\n",
    "        # Step 6: Map results back to this group\n",
    "        result_df.loc[group_data.index, 'reconstruction_error'] = errors\n",
    "        result_df.loc[group_data.index[local_anomalies_mask], 'is_anomaly'] = 1\n",
    "\n",
    "        print(f\"Cluster {group_id} anomalies: {local_anomalies_mask.sum()}\")\n",
    "\n",
    "    return result_df[['reconstruction_error', 'is_anomaly']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_anomaly_columns_to_original_df(data_original, anomalies_df, new_cols):\n",
    "    \"\"\"\n",
    "    Adds only the new anomaly columns to the original DataFrame,\n",
    "    skipping any that already exist.\n",
    "\n",
    "    Parameters:\n",
    "        data_original (pd.DataFrame): Original DataFrame (e.g., data_22)\n",
    "        anomalies_df (pd.DataFrame): DataFrame with predicted anomaly results\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with only the new anomaly columns added\n",
    "    \"\"\"\n",
    "    # List of expected anomaly-related columns\n",
    "    # new_cols = ['anomaly_score', 'is_anomaly', 'is_anomaly_flag']\n",
    "\n",
    "    # Check which columns are missing in data_original\n",
    "    cols_to_add = [col for col in new_cols if col not in data_original.columns]\n",
    "\n",
    "    if not cols_to_add:\n",
    "        print(\"\\n✅ All anomaly columns already exist. No new columns to add.\")\n",
    "        return data_original\n",
    "\n",
    "    print(f\"\\n➕ Adding the following columns to the original DataFrame: {cols_to_add}\")\n",
    "\n",
    "    # Join only the missing columns\n",
    "    data_with_anomalies = data_original.join(anomalies_df[cols_to_add])\n",
    "\n",
    "    return data_with_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run anomaly detection on both subsets\n",
    "manual_anomalies = detect_local_anomalies_with_pca(df_manual, group_col='Cluster_ID')\n",
    "kmeans_anomalies = detect_local_anomalies_with_pca(df_k_means, group_col='K_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['reconstruction_error', 'is_anomaly']\n",
    "combined = pd.concat([manual_anomalies[new_cols], kmeans_anomalies[new_cols]], axis=0)\n",
    "combined[combined['is_anomaly']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add only the missing anomaly columns to original data_22\n",
    "all_outliers = add_anomaly_columns_to_original_df(sales_df, combined, new_cols)\n",
    "all_outliers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = all_outliers.head(100).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "# table_name=\"anomaly_res_pca_manual_k\"\n",
    "\n",
    "# sql_db.fn_create_new_table_from_df(table_name=table_name, df=sub_df, auto_data_type=True)\n",
    "# res=sql_db.fn_append_df_to_table(table_name=table_name, df=sub_df)\n",
    "# print(res)\n",
    "\n",
    "# 8 min"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Outlier Factor<br>\n",
    "LOF ≈ 1 : Point has similar density as its neighbors → Not an outlier<br>\n",
    "LOF < 1 : Point is denser than neighbors → Inlier<br>\n",
    "LOF > 1 : Point is less dense than neighbors → Potential outlier<br>\n",
    "Higher LOF values indicate stronger anomalies.<br>\n",
    "\n",
    "\n",
    "Lower n_neighbors to detect subtle local anomalies. Higher n_neighbors for more stable, global patterns. Smaller n_neighbors: More localized anomalies are detected. Larger n_neighbors: Detects global outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"  # if using Intel MKL\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "import numpy as np\n",
    "# Your code here\n",
    "def detect_outliers_lof(sales_df, data, contamination=0.01, n_neighbors=40):\n",
    "    \"\"\"\n",
    "    Detects outliers in the dataset using Local Outlier Factor (LOF) \n",
    "    and adds a new column 'is_anomaly' to the original DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        sales_df (pd.DataFrame): Original DataFrame to which the 'is_anomaly' column will be added.\n",
    "        data (pd.DataFrame): Input features (numeric columns only) used for outlier detection.\n",
    "        contamination (float): Proportion of outliers in the data (default 0.01).\n",
    "        n_neighbors (int): Number of neighbors to consider for LOF (default 40).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with a new 'is_anomaly' column.\n",
    "    \"\"\"\n",
    "    new_df = sales_df.copy()\n",
    "    lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    y_pred = lof.fit_predict(data)\n",
    "\n",
    "    # Add the 'is_anomaly' column to the original DataFrame\n",
    "    new_df['is_anomaly'] = (y_pred == -1)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outliers = detect_outliers_lof(sales_df, df_numeric)\n",
    "all_outliers[all_outliers['is_anomaly']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "table_name=\"anomaly_res_lof_full\"\n",
    "\n",
    "sql_db.fn_create_new_table_from_df(table_name=table_name, df=all_outliers, auto_data_type=True)\n",
    "res=sql_db.fn_append_df_to_table(table_name=table_name, df=all_outliers)\n",
    "print(res)\n",
    "\n",
    "# 8 min"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K cluster wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_grouped_outliers_lof(original, data, group_col, contamination=0.01, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Detects outliers within each group using Local Outlier Factor (LOF)\n",
    "    and adds a new 'is_anomaly' column to the original DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        sales_df (pd.DataFrame): Original DataFrame to which the 'is_anomaly' column will be added.\n",
    "        df_numeric (pd.DataFrame): DataFrame containing only numeric feature columns for LOF.\n",
    "        group_col (str or list): Column(s) defining the group/cluster.\n",
    "        contamination (float): Proportion of outliers in each group (default 0.1).\n",
    "        n_neighbors (int): Number of neighbors to consider for LOF (default 20).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Modified sales_df with an added 'is_anomaly' column.\n",
    "    \"\"\"\n",
    "    # Initialize the is_anomaly column if not already present\n",
    "    new_df = original.copy()\n",
    "    new_df['is_anomaly'] = False\n",
    "\n",
    "    # Group by the specified group column(s)\n",
    "    for group_name, group_indices in data.groupby(group_col).groups.items():\n",
    "        group_features = data.loc[group_indices]\n",
    "\n",
    "        # Adjust n_neighbors for small groups\n",
    "        effective_n_neighbors = min(n_neighbors, len(group_features) - 1)\n",
    "        if effective_n_neighbors < 1:\n",
    "            print(f\"Cluster {group_name}: 0 outliers (skipped due to insufficient samples)\")\n",
    "            continue  # Skip groups with only one sample\n",
    "\n",
    "        lof = LocalOutlierFactor(n_neighbors=effective_n_neighbors, contamination=contamination)\n",
    "        y_pred = lof.fit_predict(group_features)\n",
    "\n",
    "        # Mark outliers in the original DataFrame\n",
    "        is_outlier = (y_pred == -1)\n",
    "        new_df.loc[group_indices, 'is_anomaly'] = is_outlier\n",
    "\n",
    "        # Count and print outlier count for this group\n",
    "        num_outliers = sum(is_outlier)\n",
    "        print(f\"Cluster {group_name}: {num_outliers} outliers\")\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outliers = detect_grouped_outliers_lof(sales_df, df_numeric, group_col='K_cluster')\n",
    "all_outliers[all_outliers['is_anomaly']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "table_name=\"anomaly_res_lof_k\"\n",
    "\n",
    "sql_db.fn_create_new_table_from_df(table_name=table_name, df=all_outliers, auto_data_type=True)\n",
    "res=sql_db.fn_append_df_to_table(table_name=table_name, df=all_outliers)\n",
    "print(res)\n",
    "\n",
    "# 8 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outliers.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual + K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual = df_numeric[df_numeric['K_cluster'].isna()]\n",
    "df_k_means = df_numeric[df_numeric['K_cluster'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning df_manual\n",
    "# Apply fillna with 0 to all except column exclude_col (df_manual)\n",
    "exclude_col = 'K_cluster'\n",
    "\n",
    "cols_to_fill = [col for col in df_manual.columns if col != exclude_col]\n",
    "df_manual[cols_to_fill] = df_manual[cols_to_fill].fillna(0)\n",
    "\n",
    "# Remove K_cluster from manual feature df\n",
    "if 'K_cluster' in df_manual:\n",
    "    print('True')\n",
    "    df_manual = df_manual.drop('K_cluster', axis=1)\n",
    "    print('Removed')\n",
    "\n",
    "# Check for NaNs\n",
    "print(\"Number of NaN values:\", np.isnan(df_manual).sum().sum())\n",
    "\n",
    "# Check for Infs\n",
    "print(\"Number of Inf values:\", np.isinf(df_manual).sum().sum())\n",
    "df_manual.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fillna with 0 to all except column exclude_col (df_k_means)\n",
    "exclude_col = 'K_cluster'\n",
    "\n",
    "cols_to_fill = [col for col in df_k_means.columns if col != exclude_col]\n",
    "df_k_means[cols_to_fill] = df_k_means[cols_to_fill].fillna(0)\n",
    "\n",
    "if 'Cluster_ID' in df_k_means:\n",
    "    print('True')\n",
    "    df_k_means = df_k_means.drop('Cluster_ID', axis=1)\n",
    "    print('Removed')\n",
    "    \n",
    "# Check for NaNs\n",
    "print(\"Number of NaN values:\", np.isnan(df_k_means).sum().sum())\n",
    "\n",
    "# Check for Infs\n",
    "print(\"Number of Inf values:\", np.isinf(df_k_means).sum().sum())\n",
    "df_k_means.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1 = detect_grouped_outliers_lof(df_manual, df_manual, group_col='Cluster_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2 = detect_grouped_outliers_lof(df_k_means, df_k_means, group_col='K_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['is_anomaly']\n",
    "combined = pd.concat([res_1[new_cols], res_2[new_cols]], axis=0)\n",
    "combined[combined['is_anomaly']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_anomaly_columns_to_original_df(data_original, anomalies_df, new_cols):\n",
    "    \"\"\"\n",
    "    Adds only the new anomaly columns to the original DataFrame,\n",
    "    skipping any that already exist.\n",
    "\n",
    "    Parameters:\n",
    "        data_original (pd.DataFrame): Original DataFrame (e.g., data_22)\n",
    "        anomalies_df (pd.DataFrame): DataFrame with predicted anomaly results\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with only the new anomaly columns added\n",
    "    \"\"\"\n",
    "    # List of expected anomaly-related columns\n",
    "    # new_cols = ['anomaly_score', 'is_anomaly', 'is_anomaly_flag']\n",
    "\n",
    "    # Check which columns are missing in data_original\n",
    "    cols_to_add = [col for col in new_cols if col not in data_original.columns]\n",
    "\n",
    "    if not cols_to_add:\n",
    "        print(\"\\n✅ All anomaly columns already exist. No new columns to add.\")\n",
    "        return data_original\n",
    "\n",
    "    print(f\"\\n➕ Adding the following columns to the original DataFrame: {cols_to_add}\")\n",
    "\n",
    "    # Join only the missing columns\n",
    "    data_with_anomalies = data_original.join(anomalies_df[cols_to_add])\n",
    "\n",
    "    return data_with_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outliers = add_anomaly_columns_to_original_df(sales_df, combined, new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "table_name=\"anomaly_res_lof_manual_k\"\n",
    "\n",
    "sql_db.fn_create_new_table_from_df(table_name=table_name, df=all_outliers, auto_data_type=True)\n",
    "res=sql_db.fn_append_df_to_table(table_name=table_name, df=all_outliers)\n",
    "print(res)\n",
    "\n",
    "# 8 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is true labels that reveal if data is anomalous or not\n",
    "\n",
    "# Define custom scorer for LOF\n",
    "def lof_custom_scorer(estimator, X):\n",
    "    scores = -estimator.negative_outlier_factor_  # Lower is better\n",
    "    threshold = np.percentile(scores, 100 * estimator.contamination)\n",
    "    y_pred = (scores > threshold).astype(int)  # 1 = outlier\n",
    "    return f1_score(y_true, y_pred)\n",
    "\n",
    "# Sample Data\n",
    "X = pd.DataFrame({\n",
    "    'x1': [1, 2, 2, 3, 100],\n",
    "    'x2': [1, 2, 3, 3, 100]\n",
    "})\n",
    "y_true = [0, 0, 0, 0, 1]  # True labels: 1 = outlier\n",
    "\n",
    "# Wrap scorer\n",
    "custom_scorer = make_scorer(lof_custom_scorer, greater_is_better=True)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [5, 10, 20],\n",
    "    'contamination': [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "# Initialize LOF model\n",
    "lof = LocalOutlierFactor()\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lof,\n",
    "    param_grid=param_grid,\n",
    "    scoring=custom_scorer,\n",
    "    cv=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_lof_scores(data, contamination_range=[0.1, 0.2, 0.3, 0.4]):\n",
    "    lof_scores = []\n",
    "    \n",
    "    for contam in contamination_range:\n",
    "        lof = LocalOutlierFactor(contamination=contam)\n",
    "        lof.fit(data)\n",
    "        lof_scores.append(-lof.negative_outlier_factor_)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, contam in enumerate(contamination_range):\n",
    "        plt.plot(lof_scores[i], label=f'Contamination={contam}')\n",
    "    \n",
    "    plt.title(\"LOF Scores Across Contamination Levels\")\n",
    "    plt.xlabel(\"Data Point Index\")\n",
    "    plt.ylabel(\"LOF Score\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_lof_scores(df_numeric)\n",
    "# 45 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lof_by_contamination(X, contamination_values=[0.2, 0.3, 0.4]):\n",
    "    fig, axes = plt.subplots(1, len(contamination_values), figsize=(18, 5), sharey=True)\n",
    "    \n",
    "    for i, contam in enumerate(contamination_values):\n",
    "        lof = LocalOutlierFactor(contamination=contam)\n",
    "        y_pred = lof.fit_predict(X)\n",
    "        scores = -lof.negative_outlier_factor_\n",
    "\n",
    "        # Plot histogram of LOF scores\n",
    "        sns.histplot(scores, ax=axes[i], kde=True, bins=30, color='skyblue')\n",
    "        threshold = np.quantile(scores, 1 - contam)\n",
    "        axes[i].axvline(threshold, color='red', linestyle='--', label=f'Threshold ({contam})')\n",
    "        axes[i].set_title(f\"Contamination={contam}\")\n",
    "        axes[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Distribution of LOF Scores by Contamination Level\", y=1.05)\n",
    "    plt.show()\n",
    "\n",
    "plot_lof_by_contamination(df_numeric)\n",
    "# 33-35 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lof_by_n_neighbors(X, n_neighbors_list=[5, 10, 20, 40]):\n",
    "    fig, axes = plt.subplots(1, len(n_neighbors_list), figsize=(20, 5))\n",
    "    \n",
    "    for i, n in enumerate(n_neighbors_list):\n",
    "        lof = LocalOutlierFactor(n_neighbors=n)\n",
    "        lof.fit(X)\n",
    "        scores = -lof.negative_outlier_factor_\n",
    "        \n",
    "        # Scatter plot with LOF scores as color\n",
    "        sc = axes[i].scatter(X.iloc[:, 0], X.iloc[:, 1], c=scores, cmap='viridis', s=50)\n",
    "        axes[i].set_title(f'n_neighbors = {n}')\n",
    "        plt.colorbar(sc, ax=axes[i], label='LOF Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"LOF Scores by Number of Neighbors\", y=1.05)\n",
    "    plt.show()\n",
    "\n",
    "plot_lof_by_n_neighbors(df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_numeric.drop('K_cluster', axis=1)\n",
    "df_numeric.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92504 entries, 0 to 92503\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   accdocno  92504 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 722.8 KB\n"
     ]
    }
   ],
   "source": [
    "sql_db=Conn_ODBC(database=\"JE_ML_2025\")\n",
    "\n",
    "conn=sql_db.odbc_conn_db_pyodbc()\n",
    "\n",
    "sql_query=f\"\"\"\n",
    "select distinct accdocno from data_ishi_GL_cleaned_2019 where accdocno like '99%' and DocNoOfClearingDoc in (\n",
    "select DISTINCT AccDocNo from data_ishi_GL_cleaned_2019 where AccDocNo in \n",
    "(SELECT DISTINCT DocNoOfClearingDoc FROM data_ishi_GL_cleaned_2019 WHERE DocNoOfClearingDoc IS NOT NULL AND AccDocNo LIKE '99%')\n",
    "AND REPLACE(REPLACE(RefKeyForLineItem, ' ',''), '/','') LIKE '%OPMT%'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "overpayment_accdocnos = sql_db.odbc_run_sql(conn, sql_query, return_result=True)\n",
    "conn.close()\n",
    "overpayment_accdocnos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_db=Conn_ODBC(database=\"JE_ML_2025\")\n",
    "\n",
    "conn=sql_db.odbc_conn_db_pyodbc()\n",
    "\n",
    "sql_query=f\"\"\"\n",
    "select distinct accdocno from data_ishi_GL_cleaned_2019 where AccDocNo in (\n",
    "select distinct [Invoice Number] from data_ishi_ZOTC_comb_2019 where [IS Rep] like '%seok yee%' and Vendor like '%hp%'\n",
    ")\n",
    "\"\"\"\n",
    "hp = sql_db.odbc_run_sql(conn, sql_query, return_result=True)\n",
    "conn.close()\n",
    "\n",
    "hp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_db=Conn_ODBC(database=\"JE_ML_2025\")\n",
    "\n",
    "conn=sql_db.odbc_conn_db_pyodbc()\n",
    "\n",
    "sql_query=f\"\"\"\n",
    "select distinct accdocno from data_ishi_GL_cleaned_2019 where AccDocNo in (\n",
    "select distinct [Invoice Number] from data_ishi_ZOTC_comb_2019 where [IS Rep] like '%seok yee%' and Vendor like '%microsoft%'\n",
    ")\n",
    "\"\"\"\n",
    "microsoft=sql_db.odbc_run_sql(conn, sql_query, return_result=True)\n",
    "\n",
    "microsoft.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_df = all_outliers[all_outliers['is_anomaly'] == 1].copy()\n",
    "anomaly_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking WC in customer PO number\n",
    "def contains_wc(lst):\n",
    "    if not isinstance(lst, list):\n",
    "        return False\n",
    "    return any(isinstance(s, str) and 'WC' in s.upper() for s in lst)\n",
    "\n",
    "# Testing\n",
    "test = all_outliers['Customer PO Number'].apply(contains_wc)\n",
    "test[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sets for fast lookup\n",
    "hp_docs = (\n",
    "    set(hp['accdocno'].dropna().astype(str).str.strip().str.upper())\n",
    "    if hp is not None and 'accdocno' in hp.columns else set()\n",
    ")\n",
    "microsoft_docs = (\n",
    "    set(microsoft['accdocno'].dropna().astype(str).str.strip().str.upper())\n",
    "    if microsoft is not None and 'accdocno' in microsoft.columns else set()\n",
    ")\n",
    "\n",
    "people = ['kam keong choy','pooi yee ho','seok yee chow']\n",
    "# kam keong choy is also an OS rep\n",
    "\n",
    "def check_is_rep_and_accdocno(is_rep_val, accdocno_val):\n",
    "    # Extract IS Rep name\n",
    "    if isinstance(is_rep_val, list) and len(is_rep_val) > 0:\n",
    "        rep_name = str(is_rep_val[0]).strip()\n",
    "    elif pd.notna(is_rep_val):\n",
    "        rep_name = str(is_rep_val).strip()\n",
    "    else:\n",
    "        return False, \"\"\n",
    "\n",
    "    # Check if IS Rep is in the allowed list (case-insensitive)\n",
    "    if rep_name.lower() not in [p.lower() for p in people]:\n",
    "        return False, \"\"\n",
    "\n",
    "    # Normalize AccDocNo\n",
    "    accdocno_str = str(accdocno_val).strip().upper() if pd.notna(accdocno_val) else \"\"\n",
    "\n",
    "    # Check which source it belongs to\n",
    "    if accdocno_str in hp_docs:\n",
    "        return True, f\"{rep_name}, hp\"\n",
    "    elif accdocno_str in microsoft_docs:\n",
    "        return True, f\"{rep_name}, microsoft\"\n",
    "    else:\n",
    "        return False, \"\"  # No match if AccDocNo not in either\n",
    "    \n",
    "print(len(hp_docs))\n",
    "print(len(microsoft_docs))\n",
    "\n",
    "# Testing\n",
    "match_results = anomaly_df.apply(\n",
    "    lambda row: check_is_rep_and_accdocno(row['IS Rep'], row['AccDocNo']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter rows where the first element of the tuple is True\n",
    "matched_df = match_results[match_results.apply(lambda x: x[0])]\n",
    "\n",
    "# Optional: Extract the source info (second element of the tuple)\n",
    "# matched_df['source_info'] = matched_df['match_result'].apply(lambda x: x[1])\n",
    "\n",
    "# Display result\n",
    "matched_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_os_rep(val):\n",
    "    # Handle list or pd.Series: extract first element if non-empty, else use None\n",
    "    if isinstance(val, (list, pd.Series)):\n",
    "        val = val[0] if len(val) > 0 else None\n",
    "    # Now convert to string only if not null/None, otherwise use empty string\n",
    "    val = str(val).strip().lower() if pd.notna(val) else \"\"\n",
    "    return val in people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_probability_column(df):\n",
    "    # Initialize probability column with 0s\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "    df['probability'] = 0\n",
    "    df['matched_conditions'] = [[] for _ in range(len(df))]  # List of strings for each row\n",
    "\n",
    "    # Merged Condition 1 & 2: Either Carrier Key Desc == 'WILL CALL' OR Customer PO has 'WC'\n",
    "    cond1_met = pd.Series([False] * len(df))\n",
    "    cond2_met = pd.Series([False] * len(df))\n",
    "\n",
    "    if 'Carrier Key Desc' in df.columns:\n",
    "        carrier_desc = df['Carrier Key Desc'].astype(str).str.strip().str.upper()\n",
    "        cond1_met = (carrier_desc == 'WILL CALL') | (carrier_desc == 'WILLCALL')  # Handle minor variation\n",
    "        cond1_met = cond1_met.fillna(False)\n",
    "\n",
    "    if 'Customer PO Number' in df.columns:\n",
    "        cond2_met = df['Customer PO Number'].apply(contains_wc)\n",
    "        cond2_met = cond2_met.fillna(False)\n",
    "\n",
    "    # Combined condition: if either is True, add 1 to probability\n",
    "    combined_cond = cond1_met | cond2_met\n",
    "    df['probability'] += combined_cond.astype(int)\n",
    "\n",
    "    # For rows where either condition is True, record which ones matched\n",
    "    def update_matched_conditions(row):\n",
    "        matches = []\n",
    "        if 'Carrier Key Desc' in df.columns and row['cond1_met']:\n",
    "            matches.append('Carrier Key Desc')\n",
    "        if 'Customer PO Number' in df.columns and row['cond2_met']:\n",
    "            matches.append('Customer PO Number')\n",
    "        return matches\n",
    "\n",
    "    # Temporarily add helper columns to track which sub-condition matched\n",
    "    df['cond1_met'] = cond1_met\n",
    "    df['cond2_met'] = cond2_met\n",
    "\n",
    "    # Update matched_conditions only where combined condition is True\n",
    "    temp_matches = df[combined_cond].apply(update_matched_conditions, axis=1)\n",
    "    for idx, matches in temp_matches.items():\n",
    "        df.at[idx, 'matched_conditions'] = df.at[idx, 'matched_conditions'] + matches\n",
    "\n",
    "    # Clean up temporary columns\n",
    "    df = df.drop(['cond1_met', 'cond2_met'], axis=1)\n",
    "\n",
    "    # Condition 3: Check IS Rep and Vendor\n",
    "    if 'IS Rep' in df.columns:\n",
    "        # Apply the function row by row\n",
    "        match_results = df.apply(\n",
    "            lambda row: check_is_rep_and_accdocno(row['IS Rep'], row['AccDocNo']),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Unpack results\n",
    "        df['cond3_match'] = match_results.apply(lambda x: x[0])\n",
    "        df['cond3_label'] = match_results.apply(lambda x: x[1])\n",
    "\n",
    "        # Only update where both IS Rep and AccDocNo match\n",
    "        cond3 = df['cond3_match']\n",
    "        df['probability'] += cond3.astype(int)\n",
    "        df['probability'] += cond3.astype(int)\n",
    "        \n",
    "        for idx in df[cond3].index:\n",
    "            df.at[idx, 'matched_conditions'].append(df.at[idx, 'cond3_label'])\n",
    "\n",
    "        df = df.drop('cond3_match', axis=1)\n",
    "        df = df.drop('cond3_label', axis=1)\n",
    "\n",
    "\n",
    "    # Condition 4: Check OS Rep\n",
    "    if 'OS Rep' in df.columns:\n",
    "        def match_os_rep(val):\n",
    "            val=val[0] if val else \"\"\n",
    "            return val.strip().lower() in people\n",
    "\n",
    "        cond4 = df['OS Rep'].apply(match_os_rep)\n",
    "        cond4 = cond4.fillna(False)\n",
    "        df['probability'] += cond4.astype(int)\n",
    "        df.loc[cond4, 'matched_conditions'] = df.loc[cond4, 'matched_conditions'].apply(lambda x: x + ['OS Rep'])\n",
    "\n",
    "\n",
    "    # Condition 5: RefKeyForLineItem like O / PMT\n",
    "    if 'AccDocNo' in df.columns and overpayment_accdocnos is not None and 'accdocno' in overpayment_accdocnos.columns:\n",
    "        # Extract the set of AccDocNo values from the overpayment DataFrame\n",
    "        valid_accdocnos = set(overpayment_accdocnos['accdocno'].dropna().astype(str).str.strip().str.upper())\n",
    "        # Match if AccDocNo is in the overpayment list (case-insensitive)\n",
    "        cond5 = df['AccDocNo'].astype(str).str.strip().str.upper().isin(valid_accdocnos)\n",
    "        cond5 = cond5.fillna(False)\n",
    "        df['probability'] += cond5.astype(int)\n",
    "        df.loc[cond5, 'matched_conditions'] = df.loc[cond5, 'matched_conditions'].apply(lambda x: x + ['AccDocNo (Overpayment)'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = add_probability_column(anomaly_df)\n",
    "\n",
    "final.groupby('probability')['AccDocNo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['matched_conditions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = add_probability_column(all_outliers)\n",
    "overall.groupby('probability')['AccDocNo'].count()\n",
    "# probability\n",
    "# 0    147350\n",
    "# 1      9193\n",
    "# 2       197\n",
    "\n",
    "# probability\n",
    "# 0    137689\n",
    "# 1     18592\n",
    "# 2       442\n",
    "# 3        16\n",
    "# 4         1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall['matched_conditions'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall.to_excel(rf\"D:\\victoriaquek\\JE ML 2025\\Results\\anomaly_res_pca_full.xlsx\")\n",
    "# overall.to_excel(rf\"D:\\victoriaquek\\JE ML 2025\\Results\\anomaly_res_pca_k.xlsx\")\n",
    "# overall.to_excel(rf\"D:\\victoriaquek\\JE ML 2025\\Results\\anomaly_res_pca_manual_k.xlsx\")\n",
    "overall.to_excel(rf\"D:\\victoriaquek\\JE ML 2025\\Results\\anomaly_res_pca_manual_k_s.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
